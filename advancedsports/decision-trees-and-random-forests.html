<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 4 Decision trees and random forests | Advanced Sports Data Analysis</title>
  <meta name="description" content="This is the companion text to the University of Nebraska-Lincoln’s SPMC 460: Advanced Sports Data Analysis" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 4 Decision trees and random forests | Advanced Sports Data Analysis" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is the companion text to the University of Nebraska-Lincoln’s SPMC 460: Advanced Sports Data Analysis" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 4 Decision trees and random forests | Advanced Sports Data Analysis" />
  
  <meta name="twitter:description" content="This is the companion text to the University of Nebraska-Lincoln’s SPMC 460: Advanced Sports Data Analysis" />
  

<meta name="author" content="By Matt Waite" />


<meta name="date" content="2021-02-08" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="multiple-regression-and-feature-engineering.html"/>
<link rel="next" href="xgboost.html"/>
<script src="libs/header-attrs-2.5/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  background-color: #f8f8f8; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Advanced Sports Data Analysis</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#requirements-and-conventions"><i class="fa fa-check"></i><b>1.1</b> Requirements and Conventions</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#about-this-book"><i class="fa fa-check"></i><b>1.2</b> About this book</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="the-modeling-process.html"><a href="the-modeling-process.html"><i class="fa fa-check"></i><b>2</b> The modeling process</a>
<ul>
<li class="chapter" data-level="2.1" data-path="the-modeling-process.html"><a href="the-modeling-process.html#setting-up-the-modeling-process"><i class="fa fa-check"></i><b>2.1</b> Setting up the modeling process</a></li>
<li class="chapter" data-level="2.2" data-path="the-modeling-process.html"><a href="the-modeling-process.html#predicting-based-on-the-model"><i class="fa fa-check"></i><b>2.2</b> Predicting based on the model</a></li>
<li class="chapter" data-level="2.3" data-path="the-modeling-process.html"><a href="the-modeling-process.html#predicting-data-we-havent-seen-before"><i class="fa fa-check"></i><b>2.3</b> Predicting data we haven’t seen before</a></li>
<li class="chapter" data-level="2.4" data-path="the-modeling-process.html"><a href="the-modeling-process.html#looking-locally"><i class="fa fa-check"></i><b>2.4</b> Looking locally</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="multiple-regression-and-feature-engineering.html"><a href="multiple-regression-and-feature-engineering.html"><i class="fa fa-check"></i><b>3</b> Multiple regression and feature engineering</a>
<ul>
<li class="chapter" data-level="3.1" data-path="multiple-regression-and-feature-engineering.html"><a href="multiple-regression-and-feature-engineering.html#a-multiple-regression-speed-run"><i class="fa fa-check"></i><b>3.1</b> A multiple regression speed run</a></li>
<li class="chapter" data-level="3.2" data-path="multiple-regression-and-feature-engineering.html"><a href="multiple-regression-and-feature-engineering.html#picking-what-moves-the-needle"><i class="fa fa-check"></i><b>3.2</b> Picking what moves the needle</a></li>
<li class="chapter" data-level="3.3" data-path="multiple-regression-and-feature-engineering.html"><a href="multiple-regression-and-feature-engineering.html#feature-engineering"><i class="fa fa-check"></i><b>3.3</b> Feature engineering</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="decision-trees-and-random-forests.html"><a href="decision-trees-and-random-forests.html"><i class="fa fa-check"></i><b>4</b> Decision trees and random forests</a>
<ul>
<li class="chapter" data-level="4.1" data-path="decision-trees-and-random-forests.html"><a href="decision-trees-and-random-forests.html#an-intro-to-pre-processing"><i class="fa fa-check"></i><b>4.1</b> An intro to pre-processing</a></li>
<li class="chapter" data-level="4.2" data-path="decision-trees-and-random-forests.html"><a href="decision-trees-and-random-forests.html#decision-trees"><i class="fa fa-check"></i><b>4.2</b> Decision trees</a></li>
<li class="chapter" data-level="4.3" data-path="decision-trees-and-random-forests.html"><a href="decision-trees-and-random-forests.html#random-forest"><i class="fa fa-check"></i><b>4.3</b> Random forest</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="xgboost.html"><a href="xgboost.html"><i class="fa fa-check"></i><b>5</b> XGBoost</a></li>
<li class="chapter" data-level="6" data-path="support-vector-machines.html"><a href="support-vector-machines.html"><i class="fa fa-check"></i><b>6</b> Support Vector Machines</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Advanced Sports Data Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="decision-trees-and-random-forests" class="section level1" number="4">
<h1><span class="header-section-number">Chapter 4</span> Decision trees and random forests</h1>
<p>Tree-based algorithms are based on decision trees, which are very easy to understand. A decision tree can basically be described as a series of questions. Does this player have more or less seasons of experience? Do they have more or less minutes played? Do they play this or that position? Answer enough questions, and you can predict what that player should have.</p>
<p>The upside of decision trees is that if the model is small, you can explain it to anyone. They’re very easy to understand. The trouble with decision trees is that if the model is small, they’re a bit of a crude instrument. As such, multiple tree based methods have been developed as improvements on the humble decision tree.</p>
<p>The most common is the random forest.</p>
<p>Let’s implement one. We start with libraries.</p>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb69-1"><a href="decision-trees-and-random-forests.html#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb69-2"><a href="decision-trees-and-random-forests.html#cb69-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidymodels)</span></code></pre></div>
<p>We’ll be using college basketball games again.</p>
<pre><p><strong>For this walkthrough:</strong></p><p><a href="http://mattwaite.github.io/sportsdatafiles/cbblogs1521.csv">
  <button class="btn btn-danger"><i class="fa fa-save"></i> Download csv file</button>
</a></p></pre>
<p>Let’s load this data and add our possession metrics right away.</p>
<div class="sourceCode" id="cb70"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb70-1"><a href="decision-trees-and-random-forests.html#cb70-1" aria-hidden="true" tabindex="-1"></a>games <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">&quot;data/cbblogs1521.csv&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb70-2"><a href="decision-trees-and-random-forests.html#cb70-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(TeamFGPCT <span class="sc">&gt;</span> <span class="dv">0</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb70-3"><a href="decision-trees-and-random-forests.html#cb70-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb70-4"><a href="decision-trees-and-random-forests.html#cb70-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">TeamPossessions =</span> TeamFGA <span class="sc">-</span> TeamOffRebounds <span class="sc">+</span> TeamTurnovers <span class="sc">+</span> (.<span class="dv">475</span> <span class="sc">*</span> TeamFTA), </span>
<span id="cb70-5"><a href="decision-trees-and-random-forests.html#cb70-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">TeamPPP =</span> TeamScore<span class="sc">/</span>TeamPossessions</span>
<span id="cb70-6"><a href="decision-trees-and-random-forests.html#cb70-6" aria-hidden="true" tabindex="-1"></a>  )</span></code></pre></div>
<pre><code>## 
## ── Column specification ────────────────────────────────────────────────────────
## cols(
##   .default = col_double(),
##   Season = col_character(),
##   Date = col_date(format = &quot;&quot;),
##   TeamFull = col_character(),
##   Opponent = col_character(),
##   HomeAway = col_character(),
##   W_L = col_character(),
##   URL = col_character(),
##   Conference = col_character(),
##   Team = col_character()
## )
## ℹ Use `spec()` for the full column specifications.</code></pre>
<p>More often than not, we need to do more than just use the data we have. Often, with modeling, we need to pre-process our data. Pre-processing can mean a lot of things – fixing dates, creating new features, scaling numbers to be similar – but it’s all about making your models better.</p>
<div id="an-intro-to-pre-processing" class="section level2" number="4.1">
<h2><span class="header-section-number">4.1</span> An intro to pre-processing</h2>
<p>To simplify things, we’re going to first simplify our data. We want to start with a minimum of columns. We need the columns to help us identify individual records, we need our predictors and we need the outcome we’re trying to predict.</p>
<div class="sourceCode" id="cb72"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb72-1"><a href="decision-trees-and-random-forests.html#cb72-1" aria-hidden="true" tabindex="-1"></a>modelgames <span class="ot">&lt;-</span> games <span class="sc">%&gt;%</span></span>
<span id="cb72-2"><a href="decision-trees-and-random-forests.html#cb72-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(Team, Opponent, Date, Season, TeamScore, TeamPossessions, TeamPPP)</span></code></pre></div>
<p>Now we need to split our data into training and testing sets.</p>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb73-1"><a href="decision-trees-and-random-forests.html#cb73-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb73-2"><a href="decision-trees-and-random-forests.html#cb73-2" aria-hidden="true" tabindex="-1"></a>game_split <span class="ot">&lt;-</span> <span class="fu">initial_split</span>(modelgames, <span class="at">prop =</span> .<span class="dv">8</span>)</span>
<span id="cb73-3"><a href="decision-trees-and-random-forests.html#cb73-3" aria-hidden="true" tabindex="-1"></a>game_train <span class="ot">&lt;-</span> <span class="fu">training</span>(game_split)</span>
<span id="cb73-4"><a href="decision-trees-and-random-forests.html#cb73-4" aria-hidden="true" tabindex="-1"></a>game_test <span class="ot">&lt;-</span> <span class="fu">testing</span>(game_split)</span></code></pre></div>
<p>In simple cases, this might be enough. If the data we’re looking at is on the scale, it probably would be enough. But here we have possessions – a counting stat – and points per possession, a ratio.</p>
<p>Going forward, we’re going to make our lives easier by using workflows. Workflows in tidymodels take in a pre-processing recipe and a model definition and executes those things to make our modeling code slimmer and our lives easier.</p>
<p>To start, we need to define a pre-processsing recipe. The recipe defines a series of steps that will be performed on your data. We’ll start simple and add our formula from previous work.</p>
<div class="sourceCode" id="cb74"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb74-1"><a href="decision-trees-and-random-forests.html#cb74-1" aria-hidden="true" tabindex="-1"></a>score_rec <span class="ot">&lt;-</span> </span>
<span id="cb74-2"><a href="decision-trees-and-random-forests.html#cb74-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">recipe</span>(TeamScore <span class="sc">~</span> TeamPossessions <span class="sc">+</span> TeamPPP, <span class="at">data =</span> game_train)</span></code></pre></div>
<p>Another, more flexible way to express this, is using the . to say all predictors. In this case, all predictors is TeamPossessions and TeamPPP. What follows is the same as above, just less typing.</p>
<p>But we’re also going to add a role to our recipe. In this case, the role is how we’re going to identify each row – an ID. In this case, to identify a game, we need to know the Team, the Opponent, the Date and the Season.</p>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb75-1"><a href="decision-trees-and-random-forests.html#cb75-1" aria-hidden="true" tabindex="-1"></a>score_rec <span class="ot">&lt;-</span> </span>
<span id="cb75-2"><a href="decision-trees-and-random-forests.html#cb75-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">recipe</span>(TeamScore <span class="sc">~</span> ., <span class="at">data =</span> game_train) <span class="sc">%&gt;%</span></span>
<span id="cb75-3"><a href="decision-trees-and-random-forests.html#cb75-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">update_role</span>(Team, Opponent, Date, Season, <span class="at">new_role =</span> <span class="st">&quot;ID&quot;</span>)</span></code></pre></div>
<p>Now, we’re going to use steps to transform our data. Some models are affected by data being on different scales, so we might have to normalize them. Here’s how to do that:</p>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb76-1"><a href="decision-trees-and-random-forests.html#cb76-1" aria-hidden="true" tabindex="-1"></a>score_rec <span class="ot">&lt;-</span> </span>
<span id="cb76-2"><a href="decision-trees-and-random-forests.html#cb76-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">recipe</span>(TeamScore <span class="sc">~</span> ., <span class="at">data =</span> game_train) <span class="sc">%&gt;%</span></span>
<span id="cb76-3"><a href="decision-trees-and-random-forests.html#cb76-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">update_role</span>(Team, Opponent, Date, Season, <span class="at">new_role =</span> <span class="st">&quot;ID&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb76-4"><a href="decision-trees-and-random-forests.html#cb76-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_normalize</span>(TeamPossessions, TeamPPP)</span></code></pre></div>
<p>Now that we’ve created our pre-processing recipe, we can create our model definition.</p>
</div>
<div id="decision-trees" class="section level2" number="4.2">
<h2><span class="header-section-number">4.2</span> Decision trees</h2>
<p>As discussed earlier, decision trees are essentially a series of if/else statements. Visualized, they look like branches on a tree (thus, decision trees).</p>
<p>We’ve already defined a recipe for our data, so now we’re ready to define a model definition. First, we’ll use decision trees to prove a point.</p>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb77-1"><a href="decision-trees-and-random-forests.html#cb77-1" aria-hidden="true" tabindex="-1"></a>tree <span class="ot">&lt;-</span> <span class="fu">decision_tree</span>() <span class="sc">%&gt;%</span></span>
<span id="cb77-2"><a href="decision-trees-and-random-forests.html#cb77-2" aria-hidden="true" tabindex="-1"></a>   <span class="fu">set_engine</span>(<span class="st">&quot;rpart&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb77-3"><a href="decision-trees-and-random-forests.html#cb77-3" aria-hidden="true" tabindex="-1"></a>   <span class="fu">set_mode</span>(<span class="st">&quot;regression&quot;</span>)</span></code></pre></div>
<p>Now we’ll create the workflow. In its simplest form, the workflow defines itself as a workflow and then adds a recipe and a model definition.</p>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb78-1"><a href="decision-trees-and-random-forests.html#cb78-1" aria-hidden="true" tabindex="-1"></a> tree_wf <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">%&gt;%</span></span>
<span id="cb78-2"><a href="decision-trees-and-random-forests.html#cb78-2" aria-hidden="true" tabindex="-1"></a>   <span class="fu">add_recipe</span>(score_rec) <span class="sc">%&gt;%</span></span>
<span id="cb78-3"><a href="decision-trees-and-random-forests.html#cb78-3" aria-hidden="true" tabindex="-1"></a>   <span class="fu">add_model</span>(tree)</span></code></pre></div>
<p>Now we can fit the data with our model using the workflow. This applies our recipe to the data without us having to do it, then uses the model definition to do the fitting.</p>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb79-1"><a href="decision-trees-and-random-forests.html#cb79-1" aria-hidden="true" tabindex="-1"></a>tree_fit <span class="ot">&lt;-</span> </span>
<span id="cb79-2"><a href="decision-trees-and-random-forests.html#cb79-2" aria-hidden="true" tabindex="-1"></a>  tree_wf <span class="sc">%&gt;%</span> </span>
<span id="cb79-3"><a href="decision-trees-and-random-forests.html#cb79-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">data =</span> game_train)</span></code></pre></div>
<p>What does this produce? Here’s what a basic decision tree looks like.</p>
<div class="sourceCode" id="cb80"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb80-1"><a href="decision-trees-and-random-forests.html#cb80-1" aria-hidden="true" tabindex="-1"></a>tree_fit <span class="sc">%&gt;%</span> </span>
<span id="cb80-2"><a href="decision-trees-and-random-forests.html#cb80-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pull_workflow_fit</span>() </span></code></pre></div>
<pre><code>## parsnip model object
## 
## Fit time:  148ms 
## n= 48108 
## 
## node), split, n, deviance, yval
##       * denotes terminal node
## 
##  1) root 48108 8453411.00  71.36264  
##    2) TeamPPP&lt; -0.05416916 23154 1837015.00  62.10029  
##      4) TeamPPP&lt; -0.8976393 8875  442669.00  55.05093  
##        8) TeamPPP&lt; -1.619514 2415   82997.80  48.25756 *
##        9) TeamPPP&gt;=-1.619514 6460  206554.00  57.59056  
##         18) TeamPossessions&lt; 0.1127405 3818   53447.02  54.19487 *
##         19) TeamPossessions&gt;=0.1127405 2642   45462.49  62.49773 *
##      5) TeamPPP&gt;=-0.8976393 14279  679199.00  66.48176  
##       10) TeamPossessions&lt; 0.1886111 8556  162907.50  62.43560 *
##       11) TeamPossessions&gt;=0.1886111 5723  166805.30  72.53084 *
##    3) TeamPPP&gt;=-0.05416916 24954 2786860.00  79.95688  
##      6) TeamPossessions&lt; 0.2885382 15960  956834.70  75.38277  
##       12) TeamPPP&lt; 0.8668753 10137  257020.10  71.47529  
##         24) TeamPossessions&lt; -0.6811247 3897   60186.35  67.12163 *
##         25) TeamPossessions&gt;=-0.6811247 6240   76838.59  74.19423 *
##       13) TeamPPP&gt;=0.8668753 5823  275596.40  82.18513  
##         26) TeamPossessions&lt; -0.6700217 2393   78411.80  77.46803 *
##         27) TeamPossessions&gt;=-0.6700217 3430  106789.50  85.47609 *
##      7) TeamPossessions&gt;=0.2885382 8994  903550.10  88.07372  
##       14) TeamPPP&lt; 1.019439 6403  254741.00  83.76620  
##         28) TeamPossessions&lt; 1.413643 4914   85442.45  81.47131 *
##         29) TeamPossessions&gt;=1.413643 1489   58010.05  91.33983 *
##       15) TeamPPP&gt;=1.019439 2591  236405.90  98.71864  
##         30) TeamPPP&lt; 1.972357 2080   94394.44  95.83221 *
##         31) TeamPPP&gt;=1.972357 511   54143.22 110.46770 *</code></pre>
<p>They can be a bit tough to read, but take the bottom three nodes, starting with 15. It says if TeamPPP is greater than or equal to 1.01 – you’re scoring more than a point per possession – your score is around 98 points a game. But the terminal nodes – the actual decisions – within this branch – say if it’s less than 1.97 per possession, your score is 95.83, but if it’s greater or equal to 1.97 – and there’s 511 games where teams were scoring nearly a bucket every trip up the floor – their score is 110.47.</p>
<p>Easy to understand, right? The algorithm cuts branches when the splits stop reducing error, and there’s a limit But here’s where the crude instrument comes in.</p>
<p>Let’s use our decision tree to predict some scores.</p>
<div class="sourceCode" id="cb82"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb82-1"><a href="decision-trees-and-random-forests.html#cb82-1" aria-hidden="true" tabindex="-1"></a>treeresults <span class="ot">&lt;-</span> game_train <span class="sc">%&gt;%</span></span>
<span id="cb82-2"><a href="decision-trees-and-random-forests.html#cb82-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_cols</span>(<span class="fu">predict</span>(tree_fit, game_train))</span></code></pre></div>
<p>What are the accuracy metrics we get?</p>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb83-1"><a href="decision-trees-and-random-forests.html#cb83-1" aria-hidden="true" tabindex="-1"></a><span class="fu">metrics</span>(treeresults, <span class="at">truth =</span> TeamScore, <span class="at">estimate =</span> .pred)</span></code></pre></div>
<pre><code>## # A tibble: 3 x 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 rmse    standard       4.84 
## 2 rsq     standard       0.867
## 3 mae     standard       3.72</code></pre>
<p>Our rsquared is .8668, which would under most circumstances would be great. And our RSME says were off by almost five points on average, which is a little worse than our multiple regression analysis.</p>
<p>We can do better.</p>
</div>
<div id="random-forest" class="section level2" number="4.3">
<h2><span class="header-section-number">4.3</span> Random forest</h2>
<p>Enter the random forest. A random forest is, as the name implies, a large number of decision trees, and they use a random set of inputs. The trees all make predictions, and the wisdom of the crowds takes over. In the case of classification algorithm, the most common prediction is the one that gets chosen. In a regression model, the predictions get averaged together.</p>
<p>The random part of random forest is in how the number of tree splits get created and how the samples from the data are taken to generate the splits. They’re randomized, which has the effect of limiting the influence of a particular feature and prevents overfitting.</p>
<p>For random forests, we change the model type to rand_forest and set the engine to “ranger.” There’s multiple implementations of the random forest algorithm, and the differences between them are beyond the scope of what we’re doing here.</p>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb85-1"><a href="decision-trees-and-random-forests.html#cb85-1" aria-hidden="true" tabindex="-1"></a>rf_mod <span class="ot">&lt;-</span> <span class="fu">rand_forest</span>() <span class="sc">%&gt;%</span></span>
<span id="cb85-2"><a href="decision-trees-and-random-forests.html#cb85-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;ranger&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb85-3"><a href="decision-trees-and-random-forests.html#cb85-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;regression&quot;</span>)</span></code></pre></div>
<p>And now we can create our workflow. We first need to define it as a workflow, then add the model and add the recipe.</p>
<div class="sourceCode" id="cb86"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb86-1"><a href="decision-trees-and-random-forests.html#cb86-1" aria-hidden="true" tabindex="-1"></a>score_wflow <span class="ot">&lt;-</span> </span>
<span id="cb86-2"><a href="decision-trees-and-random-forests.html#cb86-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">workflow</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb86-3"><a href="decision-trees-and-random-forests.html#cb86-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_recipe</span>(score_rec) <span class="sc">%&gt;%</span> </span>
<span id="cb86-4"><a href="decision-trees-and-random-forests.html#cb86-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_model</span>(rf_mod)</span>
<span id="cb86-5"><a href="decision-trees-and-random-forests.html#cb86-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-6"><a href="decision-trees-and-random-forests.html#cb86-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-7"><a href="decision-trees-and-random-forests.html#cb86-7" aria-hidden="true" tabindex="-1"></a>score_wflow</span></code></pre></div>
<pre><code>## ══ Workflow ════════════════════════════════════════════════════════════════════
## Preprocessor: Recipe
## Model: rand_forest()
## 
## ── Preprocessor ────────────────────────────────────────────────────────────────
## 1 Recipe Step
## 
## ● step_normalize()
## 
## ── Model ───────────────────────────────────────────────────────────────────────
## Random Forest Model Specification (regression)
## 
## Computational engine: ranger</code></pre>
<p>With the workflow in place, we can fit our model.</p>
<p>Note: this can make your laptop fan go wheeeeee.</p>
<div class="sourceCode" id="cb88"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb88-1"><a href="decision-trees-and-random-forests.html#cb88-1" aria-hidden="true" tabindex="-1"></a>score_fit <span class="ot">&lt;-</span> </span>
<span id="cb88-2"><a href="decision-trees-and-random-forests.html#cb88-2" aria-hidden="true" tabindex="-1"></a>  score_wflow <span class="sc">%&gt;%</span> </span>
<span id="cb88-3"><a href="decision-trees-and-random-forests.html#cb88-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">data =</span> game_train)</span></code></pre></div>
<p>Now we can use a use a new function – pull_workflow_fit, which pulls the fit stats we want to see to evaluate it.</p>
<div class="sourceCode" id="cb89"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb89-1"><a href="decision-trees-and-random-forests.html#cb89-1" aria-hidden="true" tabindex="-1"></a>score_fit <span class="sc">%&gt;%</span> </span>
<span id="cb89-2"><a href="decision-trees-and-random-forests.html#cb89-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pull_workflow_fit</span>() </span></code></pre></div>
<pre><code>## parsnip model object
## 
## Fit time:  16s 
## Ranger result
## 
## Call:
##  ranger::ranger(x = maybe_data_frame(x), y = y, num.threads = 1,      verbose = FALSE, seed = sample.int(10^5, 1)) 
## 
## Type:                             Regression 
## Number of trees:                  500 
## Sample size:                      48108 
## Number of independent variables:  2 
## Mtry:                             1 
## Target node size:                 5 
## Variable importance mode:         none 
## Splitrule:                        variance 
## OOB prediction error (MSE):       0.1445086 
## R squared (OOB):                  0.9991776</code></pre>
<p>Similar to previous work, we can bind the prediction to our training data and evaluate the model.</p>
<div class="sourceCode" id="cb91"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb91-1"><a href="decision-trees-and-random-forests.html#cb91-1" aria-hidden="true" tabindex="-1"></a>trainresults <span class="ot">&lt;-</span> game_train <span class="sc">%&gt;%</span></span>
<span id="cb91-2"><a href="decision-trees-and-random-forests.html#cb91-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_cols</span>(<span class="fu">predict</span>(score_fit, game_train))</span></code></pre></div>
<div class="sourceCode" id="cb92"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb92-1"><a href="decision-trees-and-random-forests.html#cb92-1" aria-hidden="true" tabindex="-1"></a><span class="fu">metrics</span>(trainresults, <span class="at">truth =</span> TeamScore, <span class="at">estimate =</span> .pred)</span></code></pre></div>
<pre><code>## # A tibble: 3 x 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 rmse    standard      0.197 
## 2 rsq     standard      1.00  
## 3 mae     standard      0.0555</code></pre>
<p>Note: The RMSE for this model is down to .2. The R-squared is absurdly high.</p>
<p>But how does this model handle data it hasn’t seen before?</p>
<div class="sourceCode" id="cb94"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb94-1"><a href="decision-trees-and-random-forests.html#cb94-1" aria-hidden="true" tabindex="-1"></a>testresults <span class="ot">&lt;-</span> game_test <span class="sc">%&gt;%</span></span>
<span id="cb94-2"><a href="decision-trees-and-random-forests.html#cb94-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_cols</span>(<span class="fu">predict</span>(score_fit, game_test))</span></code></pre></div>
<div class="sourceCode" id="cb95"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb95-1"><a href="decision-trees-and-random-forests.html#cb95-1" aria-hidden="true" tabindex="-1"></a><span class="fu">metrics</span>(testresults, <span class="at">truth =</span> TeamScore, <span class="at">estimate =</span> .pred)</span></code></pre></div>
<pre><code>## # A tibble: 3 x 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 rmse    standard      0.281 
## 2 rsq     standard      1.00  
## 3 mae     standard      0.0819</code></pre>
<p>How well does the random forest algorithm do with Nebraska’s schedule in 2020-2021 prior to a month-long COVID break?</p>
<div class="sourceCode" id="cb97"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb97-1"><a href="decision-trees-and-random-forests.html#cb97-1" aria-hidden="true" tabindex="-1"></a>nu <span class="ot">&lt;-</span> games <span class="sc">%&gt;%</span> <span class="fu">filter</span>(Season <span class="sc">==</span> <span class="st">&quot;2020-2021&quot;</span>, Team <span class="sc">==</span> <span class="st">&quot;Nebraska&quot;</span>)</span>
<span id="cb97-2"><a href="decision-trees-and-random-forests.html#cb97-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb97-3"><a href="decision-trees-and-random-forests.html#cb97-3" aria-hidden="true" tabindex="-1"></a>nupreds <span class="ot">&lt;-</span> nu <span class="sc">%&gt;%</span></span>
<span id="cb97-4"><a href="decision-trees-and-random-forests.html#cb97-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">bind_cols</span>(<span class="fu">predict</span>(score_fit, nu))</span>
<span id="cb97-5"><a href="decision-trees-and-random-forests.html#cb97-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb97-6"><a href="decision-trees-and-random-forests.html#cb97-6" aria-hidden="true" tabindex="-1"></a>nupreds <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">Residual =</span> TeamScore <span class="sc">-</span> .pred) <span class="sc">%&gt;%</span> <span class="fu">arrange</span>(<span class="fu">desc</span>(Residual)) <span class="sc">%&gt;%</span> <span class="fu">select</span>(Team, Opponent, TeamScore, .pred, Residual)</span></code></pre></div>
<pre><code>## # A tibble: 12 x 5
##    Team     Opponent           TeamScore .pred  Residual
##    &lt;chr&gt;    &lt;chr&gt;                  &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;
##  1 Nebraska Doane College            110 110.   0.204   
##  2 Nebraska Ohio State                54  53.9  0.119   
##  3 Nebraska Creighton                 74  74.0  0.0346  
##  4 Nebraska Wisconsin                 53  53.0  0.0260  
##  5 Nebraska Michigan                  69  69.0  0.0203  
##  6 Nebraska North Dakota State        79  79.0 -0.000677
##  7 Nebraska Georgia Tech              64  64.0 -0.0116  
##  8 Nebraska Michigan State            77  77.0 -0.0131  
##  9 Nebraska Indiana                   76  76.0 -0.0169  
## 10 Nebraska McNeese State            102 102.  -0.0393  
## 11 Nebraska Nevada                    66  66.0 -0.0396  
## 12 Nebraska South Dakota              76  76.1 -0.0569</code></pre>
<p>Compare this to the multiple regression of the previous chapter. Take just the Doane game as an example. The multiple regression model was off by three points – which is really good when you think about it. But the random forest managed to be a tenth of that off. It’s off by just a third of a point. It can’t get much better than that.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="multiple-regression-and-feature-engineering.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="xgboost.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/03-randomforest.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["advancedsportsdataanalysis.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
