<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 4 Decision trees and random forests | Advanced Sports Data Analysis</title>
  <meta name="description" content="This is the companion text to the University of Nebraska-Lincoln’s SPMC 460: Advanced Sports Data Analysis" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 4 Decision trees and random forests | Advanced Sports Data Analysis" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is the companion text to the University of Nebraska-Lincoln’s SPMC 460: Advanced Sports Data Analysis" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 4 Decision trees and random forests | Advanced Sports Data Analysis" />
  
  <meta name="twitter:description" content="This is the companion text to the University of Nebraska-Lincoln’s SPMC 460: Advanced Sports Data Analysis" />
  

<meta name="author" content="By Matt Waite" />


<meta name="date" content="2022-02-14" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="multiple-regression.html"/>
<link rel="next" href="xgboost.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  background-color: #f8f8f8; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Advanced Sports Data Analysis</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#requirements-and-conventions"><i class="fa fa-check"></i><b>1.1</b> Requirements and Conventions</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#about-this-book"><i class="fa fa-check"></i><b>1.2</b> About this book</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="the-modeling-process-and-linear-regression.html"><a href="the-modeling-process-and-linear-regression.html"><i class="fa fa-check"></i><b>2</b> The modeling process and linear regression</a>
<ul>
<li class="chapter" data-level="2.1" data-path="the-modeling-process-and-linear-regression.html"><a href="the-modeling-process-and-linear-regression.html#feature-engineering"><i class="fa fa-check"></i><b>2.1</b> Feature engineering</a></li>
<li class="chapter" data-level="2.2" data-path="the-modeling-process-and-linear-regression.html"><a href="the-modeling-process-and-linear-regression.html#setting-up-the-modeling-process"><i class="fa fa-check"></i><b>2.2</b> Setting up the modeling process</a></li>
<li class="chapter" data-level="2.3" data-path="the-modeling-process-and-linear-regression.html"><a href="the-modeling-process-and-linear-regression.html#predicting-based-on-the-model"><i class="fa fa-check"></i><b>2.3</b> Predicting based on the model</a></li>
<li class="chapter" data-level="2.4" data-path="the-modeling-process-and-linear-regression.html"><a href="the-modeling-process-and-linear-regression.html#predicting-data-we-havent-seen-before"><i class="fa fa-check"></i><b>2.4</b> Predicting data we haven’t seen before</a></li>
<li class="chapter" data-level="2.5" data-path="the-modeling-process-and-linear-regression.html"><a href="the-modeling-process-and-linear-regression.html#looking-locally"><i class="fa fa-check"></i><b>2.5</b> Looking locally</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="multiple-regression.html"><a href="multiple-regression.html"><i class="fa fa-check"></i><b>3</b> Multiple regression</a>
<ul>
<li class="chapter" data-level="3.1" data-path="multiple-regression.html"><a href="multiple-regression.html#a-multiple-regression-speed-run"><i class="fa fa-check"></i><b>3.1</b> A multiple regression speed run</a></li>
<li class="chapter" data-level="3.2" data-path="multiple-regression.html"><a href="multiple-regression.html#picking-what-moves-the-needle"><i class="fa fa-check"></i><b>3.2</b> Picking what moves the needle</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="decision-trees-and-random-forests.html"><a href="decision-trees-and-random-forests.html"><i class="fa fa-check"></i><b>4</b> Decision trees and random forests</a>
<ul>
<li class="chapter" data-level="4.1" data-path="decision-trees-and-random-forests.html"><a href="decision-trees-and-random-forests.html#an-intro-to-pre-processing"><i class="fa fa-check"></i><b>4.1</b> An intro to pre-processing</a></li>
<li class="chapter" data-level="4.2" data-path="decision-trees-and-random-forests.html"><a href="decision-trees-and-random-forests.html#decision-trees"><i class="fa fa-check"></i><b>4.2</b> Decision trees</a></li>
<li class="chapter" data-level="4.3" data-path="decision-trees-and-random-forests.html"><a href="decision-trees-and-random-forests.html#random-forest"><i class="fa fa-check"></i><b>4.3</b> Random forest</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="xgboost.html"><a href="xgboost.html"><i class="fa fa-check"></i><b>5</b> XGBoost</a>
<ul>
<li class="chapter" data-level="5.1" data-path="xgboost.html"><a href="xgboost.html#hyperparameters"><i class="fa fa-check"></i><b>5.1</b> Hyperparameters</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Advanced Sports Data Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="decision-trees-and-random-forests" class="section level1" number="4">
<h1><span class="header-section-number">Chapter 4</span> Decision trees and random forests</h1>
<p>Tree-based algorithms are based on decision trees, which are very easy to understand. A decision tree can basically be described as a series of questions. Does this player have more or less than x seasons of experience? Do they have more or less then y minutes played? Do they play this or that position? Answer enough questions, and you can predict what that player should have on average.</p>
<p>The upside of decision trees is that if the model is small, you can explain it to anyone. They’re very easy to understand. The trouble with decision trees is that if the model is small, they’re a bit of a crude instrument. As such, multiple tree based methods have been developed as improvements on the humble decision tree.</p>
<p>The most common is the random forest.</p>
<p>Let’s implement one. We start with libraries.</p>
<div class="sourceCode" id="cb60"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb60-1"><a href="decision-trees-and-random-forests.html#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb60-2"><a href="decision-trees-and-random-forests.html#cb60-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidymodels)</span>
<span id="cb60-3"><a href="decision-trees-and-random-forests.html#cb60-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(zoo)</span>
<span id="cb60-4"><a href="decision-trees-and-random-forests.html#cb60-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(hoopR)</span>
<span id="cb60-5"><a href="decision-trees-and-random-forests.html#cb60-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(corrr)</span></code></pre></div>
<p>We’ll be using college basketball games again. Let’s load this data and add our rolling metrics right away.</p>
<div class="sourceCode" id="cb61"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb61-1"><a href="decision-trees-and-random-forests.html#cb61-1" aria-hidden="true" tabindex="-1"></a>teamgames <span class="ot">&lt;-</span> <span class="fu">load_mbb_team_box</span>(<span class="at">seasons =</span> <span class="dv">2015</span><span class="sc">:</span><span class="dv">2022</span>) <span class="sc">%&gt;%</span></span>
<span id="cb61-2"><a href="decision-trees-and-random-forests.html#cb61-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">separate</span>(field_goals_made_field_goals_attempted, <span class="at">into =</span> <span class="fu">c</span>(<span class="st">&quot;field_goals_made&quot;</span>,<span class="st">&quot;field_goals_attempted&quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb61-3"><a href="decision-trees-and-random-forests.html#cb61-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">separate</span>(three_point_field_goals_made_three_point_field_goals_attempted, <span class="at">into =</span> <span class="fu">c</span>(<span class="st">&quot;three_point_field_goals_made&quot;</span>,<span class="st">&quot;three_point_field_goals_attempted&quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb61-4"><a href="decision-trees-and-random-forests.html#cb61-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">separate</span>(free_throws_made_free_throws_attempted, <span class="at">into =</span> <span class="fu">c</span>(<span class="st">&quot;free_throws_made&quot;</span>,<span class="st">&quot;free_throws_attempted&quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb61-5"><a href="decision-trees-and-random-forests.html#cb61-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate_at</span>(<span class="dv">12</span><span class="sc">:</span><span class="dv">35</span>, as.numeric)</span></code></pre></div>
<pre><code>## Warning in mask$eval_all_mutate(quo): NAs introduced by coercion</code></pre>
<div class="sourceCode" id="cb63"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb63-1"><a href="decision-trees-and-random-forests.html#cb63-1" aria-hidden="true" tabindex="-1"></a>teamstats <span class="ot">&lt;-</span> teamgames <span class="sc">%&gt;%</span> </span>
<span id="cb63-2"><a href="decision-trees-and-random-forests.html#cb63-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(team_short_display_name) <span class="sc">%&gt;%</span></span>
<span id="cb63-3"><a href="decision-trees-and-random-forests.html#cb63-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb63-4"><a href="decision-trees-and-random-forests.html#cb63-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">team_score =</span> ((field_goals_made<span class="sc">-</span>three_point_field_goals_made) <span class="sc">*</span> <span class="dv">2</span>) <span class="sc">+</span> (three_point_field_goals_made<span class="sc">*</span><span class="dv">3</span>) <span class="sc">+</span> free_throws_made,</span>
<span id="cb63-5"><a href="decision-trees-and-random-forests.html#cb63-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">possessions =</span> field_goals_attempted <span class="sc">-</span> offensive_rebounds <span class="sc">+</span> turnovers <span class="sc">+</span> (.<span class="dv">475</span> <span class="sc">*</span> free_throws_attempted),</span>
<span id="cb63-6"><a href="decision-trees-and-random-forests.html#cb63-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">ppp =</span> team_score<span class="sc">/</span>possessions,</span>
<span id="cb63-7"><a href="decision-trees-and-random-forests.html#cb63-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">true_shooting_percentage =</span> (team_score <span class="sc">/</span> (<span class="dv">2</span><span class="sc">*</span>(field_goals_attempted <span class="sc">+</span> (.<span class="dv">44</span> <span class="sc">*</span> free_throws_attempted)))) <span class="sc">*</span> <span class="dv">100</span>,</span>
<span id="cb63-8"><a href="decision-trees-and-random-forests.html#cb63-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">turnover_pct =</span> turnovers<span class="sc">/</span>(field_goals_attempted <span class="sc">+</span> <span class="fl">0.44</span> <span class="sc">*</span> free_throws_attempted <span class="sc">+</span> turnovers),</span>
<span id="cb63-9"><a href="decision-trees-and-random-forests.html#cb63-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">free_throw_factor =</span> free_throws_made<span class="sc">/</span>field_goals_attempted,</span>
<span id="cb63-10"><a href="decision-trees-and-random-forests.html#cb63-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">rolling_shooting_percentage =</span> <span class="fu">rollmean</span>(<span class="fu">lag</span>(field_goal_pct, <span class="at">n=</span><span class="dv">1</span>), <span class="at">k=</span><span class="dv">2</span>, <span class="at">fill=</span>field_goal_pct),</span>
<span id="cb63-11"><a href="decision-trees-and-random-forests.html#cb63-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">rolling_ppp =</span> <span class="fu">rollmean</span>(<span class="fu">lag</span>(ppp, <span class="at">n=</span><span class="dv">1</span>), <span class="at">k=</span><span class="dv">2</span>, <span class="at">fill=</span>ppp),</span>
<span id="cb63-12"><a href="decision-trees-and-random-forests.html#cb63-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">rolling_true_shooting_percentage =</span> <span class="fu">rollmean</span>(<span class="fu">lag</span>(true_shooting_percentage, <span class="at">n=</span><span class="dv">1</span>), <span class="at">k=</span><span class="dv">2</span>, <span class="at">fill=</span>true_shooting_percentage),</span>
<span id="cb63-13"><a href="decision-trees-and-random-forests.html#cb63-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">rolling_turnover_percentage =</span> <span class="fu">rollmean</span>(<span class="fu">lag</span>(turnover_pct, <span class="at">n=</span><span class="dv">1</span>), <span class="at">k=</span><span class="dv">2</span>, <span class="at">fill=</span>turnover_pct),</span>
<span id="cb63-14"><a href="decision-trees-and-random-forests.html#cb63-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">rolling_free_throw_factor =</span> <span class="fu">rollmean</span>(<span class="fu">lag</span>(free_throw_factor, <span class="at">n=</span><span class="dv">1</span>), <span class="at">k=</span><span class="dv">2</span>, <span class="at">fill=</span>free_throw_factor),    </span>
<span id="cb63-15"><a href="decision-trees-and-random-forests.html#cb63-15" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> <span class="fu">ungroup</span>()</span></code></pre></div>
<p>More often than not, we need to do more than just use the data we have. Often, with modeling, we need to pre-process our data. Pre-processing can mean a lot of things – fixing dates, creating new features, scaling numbers to be similar – but it’s all about making your models better.</p>
<div id="an-intro-to-pre-processing" class="section level2" number="4.1">
<h2><span class="header-section-number">4.1</span> An intro to pre-processing</h2>
<p>To simplify things, we’re going to first simplify our data. We want to start with a minimum of columns. We need the columns to help us identify individual records, we need our predictors and we need the outcome we’re trying to predict.</p>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb64-1"><a href="decision-trees-and-random-forests.html#cb64-1" aria-hidden="true" tabindex="-1"></a>modelgames <span class="ot">&lt;-</span> teamstats <span class="sc">%&gt;%</span></span>
<span id="cb64-2"><a href="decision-trees-and-random-forests.html#cb64-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(team_short_display_name, opponent_name, game_date, season, team_score, rolling_ppp, rolling_free_throw_factor, rolling_turnover_percentage) <span class="sc">%&gt;%</span> <span class="fu">na.omit</span>()</span></code></pre></div>
<p>Now we need to split our data into training and testing sets.</p>
<div class="sourceCode" id="cb65"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb65-1"><a href="decision-trees-and-random-forests.html#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb65-2"><a href="decision-trees-and-random-forests.html#cb65-2" aria-hidden="true" tabindex="-1"></a>game_split <span class="ot">&lt;-</span> <span class="fu">initial_split</span>(modelgames, <span class="at">prop =</span> .<span class="dv">8</span>)</span>
<span id="cb65-3"><a href="decision-trees-and-random-forests.html#cb65-3" aria-hidden="true" tabindex="-1"></a>game_train <span class="ot">&lt;-</span> <span class="fu">training</span>(game_split)</span>
<span id="cb65-4"><a href="decision-trees-and-random-forests.html#cb65-4" aria-hidden="true" tabindex="-1"></a>game_test <span class="ot">&lt;-</span> <span class="fu">testing</span>(game_split)</span></code></pre></div>
<p>Going forward, we’re going to make our lives easier by using workflows. Workflows in tidymodels take in a pre-processing recipe and a model definition and executes those things to make our modeling code slimmer and our lives easier.</p>
<p>To start, we need to define a pre-processing recipe. The recipe defines a series of steps that will be performed on your data. We’ll start simple and add our formula from previous work.</p>
<div class="sourceCode" id="cb66"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb66-1"><a href="decision-trees-and-random-forests.html#cb66-1" aria-hidden="true" tabindex="-1"></a>score_rec <span class="ot">&lt;-</span> </span>
<span id="cb66-2"><a href="decision-trees-and-random-forests.html#cb66-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">recipe</span>(team_score <span class="sc">~</span> rolling_ppp <span class="sc">+</span> rolling_turnover_percentage <span class="sc">+</span> rolling_free_throw_factor, <span class="at">data =</span> game_train)</span></code></pre></div>
<p>Another, more flexible way to express this, is using the . to say all predictors. In this case, all predictors is rolling_ppp, rolling_turnover_percentage and rolling_free_throw_factor. What follows is the same as above, just less typing.</p>
<p>But we’re also going to add a role to our recipe. In this case, the role is how we’re going to identify each row – an ID. In this case, to identify a game, we need to know the Team, the Opponent, the Date and the Season. What isn’t an ID is a predictor.</p>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb67-1"><a href="decision-trees-and-random-forests.html#cb67-1" aria-hidden="true" tabindex="-1"></a>score_rec <span class="ot">&lt;-</span> </span>
<span id="cb67-2"><a href="decision-trees-and-random-forests.html#cb67-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">recipe</span>(team_score <span class="sc">~</span> ., <span class="at">data =</span> game_train) <span class="sc">%&gt;%</span></span>
<span id="cb67-3"><a href="decision-trees-and-random-forests.html#cb67-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">update_role</span>(team_short_display_name, opponent_name, game_date, season, <span class="at">new_role =</span> <span class="st">&quot;ID&quot;</span>)</span></code></pre></div>
<p>Now that we’ve created our pre-processing recipe, we can create our model definition.</p>
</div>
<div id="decision-trees" class="section level2" number="4.2">
<h2><span class="header-section-number">4.2</span> Decision trees</h2>
<p>As discussed earlier, decision trees are essentially a series of if/else statements. Visualized, they look like branches on a tree (thus, decision trees).</p>
<p>We’ve already defined a recipe for our data, so now we’re ready to define a model definition. First, we’ll use decision trees to prove a point.</p>
<div class="sourceCode" id="cb68"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb68-1"><a href="decision-trees-and-random-forests.html#cb68-1" aria-hidden="true" tabindex="-1"></a>tree <span class="ot">&lt;-</span> <span class="fu">decision_tree</span>() <span class="sc">%&gt;%</span></span>
<span id="cb68-2"><a href="decision-trees-and-random-forests.html#cb68-2" aria-hidden="true" tabindex="-1"></a>   <span class="fu">set_engine</span>(<span class="st">&quot;rpart&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb68-3"><a href="decision-trees-and-random-forests.html#cb68-3" aria-hidden="true" tabindex="-1"></a>   <span class="fu">set_mode</span>(<span class="st">&quot;regression&quot;</span>)</span></code></pre></div>
<p>Now we’ll create the workflow. In its simplest form, the workflow defines itself as a workflow and then adds a recipe and a model definition.</p>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb69-1"><a href="decision-trees-and-random-forests.html#cb69-1" aria-hidden="true" tabindex="-1"></a> tree_wf <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">%&gt;%</span></span>
<span id="cb69-2"><a href="decision-trees-and-random-forests.html#cb69-2" aria-hidden="true" tabindex="-1"></a>   <span class="fu">add_recipe</span>(score_rec) <span class="sc">%&gt;%</span></span>
<span id="cb69-3"><a href="decision-trees-and-random-forests.html#cb69-3" aria-hidden="true" tabindex="-1"></a>   <span class="fu">add_model</span>(tree)</span></code></pre></div>
<p>Now we can fit the data with our model using the workflow. This applies our recipe to the data without us having to do it, then uses the model definition to do the fitting.</p>
<div class="sourceCode" id="cb70"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb70-1"><a href="decision-trees-and-random-forests.html#cb70-1" aria-hidden="true" tabindex="-1"></a>tree_fit <span class="ot">&lt;-</span> </span>
<span id="cb70-2"><a href="decision-trees-and-random-forests.html#cb70-2" aria-hidden="true" tabindex="-1"></a>  tree_wf <span class="sc">%&gt;%</span> </span>
<span id="cb70-3"><a href="decision-trees-and-random-forests.html#cb70-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">data =</span> game_train)</span></code></pre></div>
<p>What does this produce? Here’s what a basic decision tree looks like.</p>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb71-1"><a href="decision-trees-and-random-forests.html#cb71-1" aria-hidden="true" tabindex="-1"></a>tree_fit <span class="sc">%&gt;%</span> </span>
<span id="cb71-2"><a href="decision-trees-and-random-forests.html#cb71-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pull_workflow_fit</span>() </span></code></pre></div>
<pre><code>## Warning: `pull_workflow_fit()` was deprecated in workflows 0.2.3.
## Please use `extract_fit_parsnip()` instead.</code></pre>
<pre><code>## parsnip model object
## 
## Fit time:  540ms 
## n= 69348 
## 
## node), split, n, deviance, yval
##       * denotes terminal node
## 
##  1) root 69348 12321820.0 71.43057  
##    2) rolling_ppp&lt; 1.017204 31940  3710380.0 63.79487  
##      4) rolling_ppp&lt; 0.9065279 11646  1167697.0 57.99596  
##        8) rolling_ppp&lt; 0.7887438 2748   260754.5 51.71288 *
##        9) rolling_ppp&gt;=0.7887438 8898   764956.0 59.93639 *
##      5) rolling_ppp&gt;=0.9065279 20294  1926322.0 67.12265 *
##    3) rolling_ppp&gt;=1.017204 37408  5159190.0 77.95014  
##      6) rolling_ppp&lt; 1.16796 28441  3101745.0 75.45846  
##       12) rolling_ppp&lt; 1.101016 18038  1840311.0 73.66016 *
##       13) rolling_ppp&gt;=1.101016 10403  1101958.0 78.57656 *
##      7) rolling_ppp&gt;=1.16796 8967  1320816.0 85.85313 *</code></pre>
<p>They can be a bit tough to read, but take the bottom three nodes. It says if rolling_ppp is greater than or equal to 1.17, your score is around 85 points a game. If it’s less than 1.17, you’ll score around 76 points.</p>
<p>Easy to understand, right? The algorithm cuts branches when the splits stop reducing error, and there’s a limit But here’s where the crude instrument comes in.</p>
<p>Let’s use our decision tree to predict some scores.</p>
<div class="sourceCode" id="cb74"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb74-1"><a href="decision-trees-and-random-forests.html#cb74-1" aria-hidden="true" tabindex="-1"></a>treeresults <span class="ot">&lt;-</span> game_train <span class="sc">%&gt;%</span></span>
<span id="cb74-2"><a href="decision-trees-and-random-forests.html#cb74-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_cols</span>(<span class="fu">predict</span>(tree_fit, game_train))</span></code></pre></div>
<p>What are the accuracy metrics we get?</p>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb75-1"><a href="decision-trees-and-random-forests.html#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="fu">metrics</span>(treeresults, <span class="at">truth =</span> team_score, <span class="at">estimate =</span> .pred)</span></code></pre></div>
<pre><code>## # A tibble: 3 × 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 rmse    standard      10.2  
## 2 rsq     standard       0.414
## 3 mae     standard       7.95</code></pre>
<p>Our rsquared is about .40, which isn’t terrible. And our MAE says we’re off by 8 points on average, but our RSME says were off by 10.3 points on a different average, indicating there’s some big misses.</p>
<p>We can do better.</p>
</div>
<div id="random-forest" class="section level2" number="4.3">
<h2><span class="header-section-number">4.3</span> Random forest</h2>
<p>Enter the random forest. A random forest is, as the name implies, a large number of decision trees, and they use a random set of inputs. The algorithm creates a large number of randomly selected training inputs, and randomly chooses the feature input for each branch, creating predictions. The goal is to create uncorrelated forests of trees. The trees all make predictions, and the wisdom of the crowds takes over. In the case of classification algorithm, the most common prediction is the one that gets chosen. In a regression model, the predictions get averaged together.</p>
<p>The random part of random forest is in how the number of tree splits get created and how the samples from the data are taken to generate the splits. They’re randomized, which has the effect of limiting the influence of a particular feature and prevents overfitting – where your predictions are so tailored to your training data that they miss badly on the test data.</p>
<p>For random forests, we change the model type to rand_forest and set the engine to “ranger.” There’s multiple implementations of the random forest algorithm, and the differences between them are beyond the scope of what we’re doing here.</p>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb77-1"><a href="decision-trees-and-random-forests.html#cb77-1" aria-hidden="true" tabindex="-1"></a>rf_mod <span class="ot">&lt;-</span> <span class="fu">rand_forest</span>() <span class="sc">%&gt;%</span></span>
<span id="cb77-2"><a href="decision-trees-and-random-forests.html#cb77-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;ranger&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb77-3"><a href="decision-trees-and-random-forests.html#cb77-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;regression&quot;</span>)</span></code></pre></div>
<p>And now we can create our workflow. We first need to define it as a workflow, then add the model and add the recipe.</p>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb78-1"><a href="decision-trees-and-random-forests.html#cb78-1" aria-hidden="true" tabindex="-1"></a>score_wflow <span class="ot">&lt;-</span> </span>
<span id="cb78-2"><a href="decision-trees-and-random-forests.html#cb78-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">workflow</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb78-3"><a href="decision-trees-and-random-forests.html#cb78-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_recipe</span>(score_rec) <span class="sc">%&gt;%</span> </span>
<span id="cb78-4"><a href="decision-trees-and-random-forests.html#cb78-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_model</span>(rf_mod)</span>
<span id="cb78-5"><a href="decision-trees-and-random-forests.html#cb78-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-6"><a href="decision-trees-and-random-forests.html#cb78-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-7"><a href="decision-trees-and-random-forests.html#cb78-7" aria-hidden="true" tabindex="-1"></a>score_wflow</span></code></pre></div>
<pre><code>## ══ Workflow ════════════════════════════════════════════════════════════════════
## Preprocessor: Recipe
## Model: rand_forest()
## 
## ── Preprocessor ────────────────────────────────────────────────────────────────
## 0 Recipe Steps
## 
## ── Model ───────────────────────────────────────────────────────────────────────
## Random Forest Model Specification (regression)
## 
## Computational engine: ranger</code></pre>
<p>With the workflow in place, we can fit our model.</p>
<p>Note: this can make your laptop fan go wheeeeee.</p>
<div class="sourceCode" id="cb80"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb80-1"><a href="decision-trees-and-random-forests.html#cb80-1" aria-hidden="true" tabindex="-1"></a>score_fit <span class="ot">&lt;-</span> </span>
<span id="cb80-2"><a href="decision-trees-and-random-forests.html#cb80-2" aria-hidden="true" tabindex="-1"></a>  score_wflow <span class="sc">%&gt;%</span> </span>
<span id="cb80-3"><a href="decision-trees-and-random-forests.html#cb80-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">data =</span> game_train)</span></code></pre></div>
<p>Now we can use a use a new function – pull_workflow_fit, which pulls the fit stats we want to see to evaluate it.</p>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb81-1"><a href="decision-trees-and-random-forests.html#cb81-1" aria-hidden="true" tabindex="-1"></a>score_fit <span class="sc">%&gt;%</span> </span>
<span id="cb81-2"><a href="decision-trees-and-random-forests.html#cb81-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pull_workflow_fit</span>() </span></code></pre></div>
<pre><code>## Warning: `pull_workflow_fit()` was deprecated in workflows 0.2.3.
## Please use `extract_fit_parsnip()` instead.</code></pre>
<pre><code>## parsnip model object
## 
## Fit time:  1m 3.2s 
## Ranger result
## 
## Call:
##  ranger::ranger(x = maybe_data_frame(x), y = y, num.threads = 1,      verbose = FALSE, seed = sample.int(10^5, 1)) 
## 
## Type:                             Regression 
## Number of trees:                  500 
## Sample size:                      69348 
## Number of independent variables:  3 
## Mtry:                             1 
## Target node size:                 5 
## Variable importance mode:         none 
## Splitrule:                        variance 
## OOB prediction error (MSE):       104.208 
## R squared (OOB):                  0.4135192</code></pre>
<p>Similar to previous work, we can bind the prediction to our training data and evaluate the model.</p>
<div class="sourceCode" id="cb84"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb84-1"><a href="decision-trees-and-random-forests.html#cb84-1" aria-hidden="true" tabindex="-1"></a>trainresults <span class="ot">&lt;-</span> game_train <span class="sc">%&gt;%</span></span>
<span id="cb84-2"><a href="decision-trees-and-random-forests.html#cb84-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_cols</span>(<span class="fu">predict</span>(score_fit, game_train))</span></code></pre></div>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb85-1"><a href="decision-trees-and-random-forests.html#cb85-1" aria-hidden="true" tabindex="-1"></a><span class="fu">metrics</span>(trainresults, <span class="at">truth =</span> team_score, <span class="at">estimate =</span> .pred)</span></code></pre></div>
<pre><code>## # A tibble: 3 × 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 rmse    standard       4.88 
## 2 rsq     standard       0.895
## 3 mae     standard       3.77</code></pre>
<p>Note: The RMSE for this model is down to 4.8. The R-squared is absurdly high.</p>
<p>But how does this model handle data it hasn’t seen before?</p>
<div class="sourceCode" id="cb87"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb87-1"><a href="decision-trees-and-random-forests.html#cb87-1" aria-hidden="true" tabindex="-1"></a>testresults <span class="ot">&lt;-</span> game_test <span class="sc">%&gt;%</span></span>
<span id="cb87-2"><a href="decision-trees-and-random-forests.html#cb87-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_cols</span>(<span class="fu">predict</span>(score_fit, game_test))</span></code></pre></div>
<div class="sourceCode" id="cb88"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb88-1"><a href="decision-trees-and-random-forests.html#cb88-1" aria-hidden="true" tabindex="-1"></a><span class="fu">metrics</span>(testresults, <span class="at">truth =</span> team_score, <span class="at">estimate =</span> .pred)</span></code></pre></div>
<pre><code>## # A tibble: 3 × 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 rmse    standard      10.3  
## 2 rsq     standard       0.414
## 3 mae     standard       8.02</code></pre>
<p>How well does the random forest algorithm do with Nebraska’s schedule in 2020-2021 prior to a month-long COVID break?</p>
<div class="sourceCode" id="cb90"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb90-1"><a href="decision-trees-and-random-forests.html#cb90-1" aria-hidden="true" tabindex="-1"></a>nu <span class="ot">&lt;-</span> modelgames <span class="sc">%&gt;%</span> <span class="fu">filter</span>(season <span class="sc">==</span> <span class="dv">2022</span>, team_short_display_name <span class="sc">==</span> <span class="st">&quot;Nebraska&quot;</span>)</span>
<span id="cb90-2"><a href="decision-trees-and-random-forests.html#cb90-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-3"><a href="decision-trees-and-random-forests.html#cb90-3" aria-hidden="true" tabindex="-1"></a>nupreds <span class="ot">&lt;-</span> nu <span class="sc">%&gt;%</span></span>
<span id="cb90-4"><a href="decision-trees-and-random-forests.html#cb90-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">bind_cols</span>(<span class="fu">predict</span>(score_fit, nu))</span>
<span id="cb90-5"><a href="decision-trees-and-random-forests.html#cb90-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-6"><a href="decision-trees-and-random-forests.html#cb90-6" aria-hidden="true" tabindex="-1"></a>nupreds <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">residual =</span> team_score <span class="sc">-</span> .pred) <span class="sc">%&gt;%</span> <span class="fu">arrange</span>(<span class="fu">desc</span>(residual)) <span class="sc">%&gt;%</span> <span class="fu">select</span>(team_short_display_name, opponent_name, team_score, .pred, residual)</span></code></pre></div>
<pre><code>## # A tibble: 25 × 5
##    team_short_display_name opponent_name    team_score .pred residual
##    &lt;chr&gt;                   &lt;chr&gt;                 &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;
##  1 Nebraska                NC State                100  74.3    25.7 
##  2 Nebraska                Kennesaw State           88  80.3     7.67
##  3 Nebraska                Michigan                 79  71.5     7.48
##  4 Nebraska                Minnesota                78  72.7     5.32
##  5 Nebraska                Michigan                 67  61.8     5.22
##  6 Nebraska                Indiana                  71  65.8     5.18
##  7 Nebraska                South Dakota             83  78.4     4.64
##  8 Nebraska                Ohio State               79  75.1     3.86
##  9 Nebraska                Sam Houston              74  70.3     3.67
## 10 Nebraska                Western Illinois         74  70.3     3.65
## # … with 15 more rows</code></pre>
<p>Compare this to the multiple regression of the previous chapter. Take just the NC State game as an example. The multiple regression model was off by 28 points – which is a lot, but it’s a triple overtime game. But the random forest managed to be off by 12.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="multiple-regression.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="xgboost.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/03-randomforest.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["advancedsportsdataanalysis.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
