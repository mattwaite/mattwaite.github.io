[["index.html", "Advanced Sports Data Analysis Modeling and Machine Learning for sports analysis in R Chapter 1 Introduction 1.1 Requirements and Conventions 1.2 About this book", " Advanced Sports Data Analysis Modeling and Machine Learning for sports analysis in R By Matt Waite 2021-01-31 Chapter 1 Introduction The 2020 college football season, for most fans, will be one to forget. The season started unevenly for most teams, schedules were shortened, non-conference games were rare, few fans saw their team play in person, all because of the COVID-19 global pandemic. For the Nebraska Cornhuskers, it was doubly forgettable. Year three of Scott Frost turned out to be another dud, with the team going 3-5. A common refrain from the coaching staff throughout the season, often after disappointing losses, was this: The team is close to turning a corner. How close? This is where modeling comes in in sports. Using modeling, we can determine what we should expect given certain inputs. To look at Nebraska’s season, let’s build a model of the season using three inputs based on narratives around the season: The offense struggled to score, the offense really struggled with turnovers, and the defense improved. The specifics of how to do this will be the subject of this whole book, so we’re going to focus on a simple explanation here. First, we’re going to create a measure of offensive efficiency – points per yard of offense. So if you roll up 500 yards of offense but only score 21 points, you’ll score .042 points per yard. A team that gains 250 yards and scores 21 points is more efficient: they score .084 points per yard. So in this model, efficient teams are good. Second, we’ll do the same for the defense, using yards allowed and the opponent’s score. Here, it’s inverted: Defenses that keep points off the board are good. Third, we’ll use turnover margin. Teams that give the ball away are bad, teams that take the ball away are good, and you want to take it away more than you give it away. Using logistic regression and these statistics, our model predicts that Nebraska is actually worse than they were: the Husker’s should have been 2-6. Giving the ball away three times and only scoring 28 points against Rutgers should have doomed the team to a bad loss at the end of the season. But, it didn’t. So how much of a corner would the team need to turn? With modeling, we can figure this out. What would Nebraska’s record if they had a +1 turnover margin and improves offensive production 10 percent? As played, our model gave Nebraska a 32 percent chance of beating Minnesota. If Nebraska were to have a +1 turnover margin, instead of the -2 that really happened, that jumps to a 40 percent chance. If Nebraska were to improve their offense just 10 percent – score a touchdown every 100 yards of offense – Nebraska wins the game. Nebraska wins, they’re 4-4 on the season (and they still don’t beat Iowa). So how close are they to turning the corner? That close. 1.1 Requirements and Conventions This book is all in the R statistical language. To follow along, you’ll do the following: Install the R language on your computer. Go to the R Project website, click download R and select a mirror closest to your location. Then download the version for your computer. Install R Studio Desktop. The free version is great. Going forward, you’ll see passages like this: install.packages(&quot;tidyverse&quot;) Don’t do it now, but that is code that you’ll need to run in your R Studio. When you see that, you’ll know what to do. 1.2 About this book This book is the collection of class materials for the author’s Advanced Sports Data Analysis class at the University of Nebraska-Lincoln’s College of Journalism and Mass Communications. There’s some things you should know about it: It is free for students. The topics will remain the same but the text is going to be constantly tinkered with. What is the work of the author is copyright Matt Waite 2021. The text is Attribution-NonCommercial-ShareAlike 4.0 International Creative Commons licensed. That means you can share it and change it, but only if you share your changes with the same license and it cannot be used for commercial purposes. I’m not making money on this so you can’t either. As such, the whole book – authored in Bookdown – is open sourced on Github. Pull requests welcomed! "],["the-modeling-process.html", "Chapter 2 The modeling process 2.1 Setting up the modeling process 2.2 Predicting based on the model 2.3 Predicting data we haven’t seen before 2.4 Looking locally", " Chapter 2 The modeling process The Nebraska men’s basketball team in 2019-2020 was … not good. The first season of Fred Hoiberg brought excitement and a lot of new faces to Lincoln, but the product on the floor didn’t go as hoped. The team finished 7-25. In the off-season, The Mayor turned over the roster (again), bringing on players who couldn’t play the previous season because of transfer rules and some new transfers who could play. As of this writing, the team has won 4 games and lost 7, and they’ve lost every Big Ten game they’ve played. But watch the team, and it’s obvious they are better. But – and this is a question we’ll explore over multiple chapters – how much better? Let’s start by looking at predicting how many points the team should score given how well they are shooting. And we’ll use this as a chance to look at linear regression modeling. If you don’t have them already installed, we’ll need the tidyverse and tidymodels for this book. install.packages(&quot;tidyverse&quot;) install.packages(&quot;tidymodels&quot;) After they’ve installed – and if you haven’t this will take a bit – load them. library(tidyverse) library(tidymodels) For this walkthrough, we’re going to use a dataset of college basketball games from the 14-15 season through the 20-21 season as of Jan. 8. For this walkthrough: Download csv file Let’s load this data and take a look at it. games &lt;- read_csv(&quot;data/cbblogs1521.csv&quot;) Any time we’re building models, we need to explore the data a bit. We can learn about our data before we try anything, which helps us learn more. A common first step? Histograms of the columns you’re looking at. A histogram groups data into bins and counts up the number of rows in that fall in the bin. Let’s first look at the histogram of points a team has scored (TeamScore). ggplot() + geom_histogram(data=games, aes(x=TeamScore)) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. First, look at the highest bar. It’s in the upper 60s, with a line near the top around 70. So a lot of college basketball teams scored that area in a game. We’re also looking at shooting perentage, so let’s make a histogram for that. ggplot() + geom_histogram(data=games, aes(x=TeamFGPCT)) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## Warning: Removed 2 rows containing non-finite values (stat_bin). First, note that 2 rows were removed for containing “non-finite values.” What does that mean? Two games don’t have shooting percentages. They got a score, but the data is missing. It’s not going to matter for modeling, so we should drop those games so they don’t cause us problems later. Second, most teams are shooting in the mid-40s per game for all shots from the floor (that’s both two point and three point shots combined). We can’t model nothing, so we need to drop the games with no stats. We can do that with a simple filter. games &lt;- games %&gt;% filter(TeamFGPCT&gt;0) Now we begin the process of creating a model. Modeling in data science has a ton of details, but the process for each model type is similar. Split your data into training and testing data sets. A common split is 80/20. Train the model on the training dataset. Evaluate the model on the training data. Apply the model to the testing data. Evaluate the model on the test data. From there, it’s how you want to use the model. We’ll walk through a simple example here, using the simplest model – a linear model. Linear models are something you’ve understood since you took middle school math and learned the equation of a line. Remember y = mx + b? It’s back. And, unlike what you complained bitterly in middle school, it’s very, very useful. What a linear model says, in words is that we can predict y if we multiply a value – a coefficient – by our x value offset with b, which is really the y-intercept, but think of it like where the line starts. What we’re trying to do here is predict how many points a team should score given their shooting prowess as a team. Or, expressed as y = mx + b: points = TeamFGPCT * ? + some starting point. Think of some starting point as what the score should be if the TeamFGPCT is zero. Should be zero, right? Intuitively, yes, but it won’t always work out so easily. 2.1 Setting up the modeling process With most modeling tasks we need to start with setting a random number seed to aid our random splitting of data into training and testing. set.seed(1234) Random numbers play a large role in a lot of data science algorithms, so setting one helps our reproducibility. After that, we split our data. There’s a number of ways to do this – R has a bunch and you’ll find all kinds of examples online – but Tidymodels has made this easy. game_split &lt;- initial_split(games, prop = .8) game_split ## &lt;Analysis/Assess/Total&gt; ## &lt;48108/12026/60134&gt; What does this mean? It says that initial_split divided the data into 48,108 games in analysis (or training), 12,026 into assess (or test), of the 60,134 total records in the dataset. But the split object isn’t useful to us. We need to assign them to dataframes. We do so like this: game_train &lt;- training(game_split) game_test &lt;- testing(game_split) Now we have two dataframes – game_train and game_test – that we can now use for modeling. First step to making a model is to set what type of model this will be. We’re going to name our model object – lm_model works because this is a linear model. We’ll use the linear_reg function in parsnip (the modeling library in Tidymodels) and set the engine to “lm.” lm_model &lt;- linear_reg() %&gt;% set_engine(&quot;lm&quot;) We can get a peek at lm_model and make sure we did everything right by just typing it and executing. lm_model ## Linear Regression Model Specification (regression) ## ## Computational engine: lm Now, let’s fit a linear model to our data. We’ll name the fitted model fit_lm and we’ll take our model object that we just created and fit it using the fit function. What goes in the fit function can be read like this: TeamScore is approximately modeled by TeamFGPCT The only thing left is to specify the dataset. fit_lm &lt;- lm_model %&gt;% fit(TeamScore ~ TeamFGPCT, data = game_train) Let’s take a look at what the fitted model object tells us about our data. tidy(fit_lm, conf.int = TRUE) ## # A tibble: 2 x 7 ## term estimate std.error statistic p.value conf.low conf.high ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 16.0 0.254 63.0 0 15.5 16.5 ## 2 TeamFGPCT 126. 0.570 221. 0 125. 127. The two most important things to see here are the terms and the estimates. Start with TeamFGPCT. What that says is for every 10 percentage points of shooting percentage, a team should score 12.6 points. HOWEVER, the intercept has something to say about this. What the intercept says is that a team with a big fat zero for shooting percentage is going to score just a hair short of 16 points. Wait … how? Well, are field goals the only way to score in basketball? No. So there’s some of your non-zero intercept. Think again about y = mx + b. We have our terms here: y is team score, m is 126.26, x is the team shooting percentage and b is 15.98997. Let’s pretend for a minute that you coached a team that shot 40 percent in college basketball. Our model predicts you would score about 66 points. But look at the confidence intervals. So our model says you’d score 66, but we’re 95 percent sure the real number is going to be between 65 and 67. 2.2 Predicting based on the model Now, we can take the model predictions and bind them to our dataset. This will be a common step throughout this book so we can see what the model predicted vs what the real world produced. trainresults &lt;- game_train %&gt;% bind_cols(predict(fit_lm, game_train)) Walking through this, we’re creating a dataframe called trainresults, which is game_train with the results of the predict function bound to it. The predict function takes two arguments – the fitted model and the dataset it is being applied to, which in this case is the same dataset. What will result is our game_train dataset with a new column: .pred Our first step in evaluating a linear model is to get the r-squared value. The yardstick library (part of Tidymodels) does this nicely. We tell it to produce metrics on a dataset, and we have to tell it what the real world result is (the truth column) and what the estimate column is (.pred). metrics(trainresults, truth = TeamScore, estimate = .pred) ## # A tibble: 3 x 3 ## .metric .estimator .estimate ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 rmse standard 9.33 ## 2 rsq standard 0.505 ## 3 mae standard 7.27 We’ll get more into RMSE and MAE later. For now, focus on rsq or r-squared. What that says is that changes in shooting percentage account for 50.48 percent of the variation in team score. That’s pretty good. Not great, but for one stat, it’s not bad. A way to look at this is with a scatterplot. The geom_smooth creates its own linear model and puts the line of best fit through our dots. ggplot() + geom_point(data=games, aes(x=TeamFGPCT, y=TeamScore)) + geom_smooth(data=games, aes(x=TeamFGPCT, y=TeamScore), method=&quot;lm&quot;, se=FALSE) ## `geom_smooth()` using formula &#39;y ~ x&#39; As you can see, there’s a lot of dots above the line and below the line. That gap is a called a residual. The residual is the actual thing minus the predicted thing. The truth minus our guess. A positive residual – in this case – is good. It means that player is scoring more than we’d predict they would. A negative residual means they’re not scoring as much as we’d expect. trainresults %&gt;% mutate(Residual = TeamScore - .pred) %&gt;% mutate(Label = case_when( Residual &gt; 0 ~ &quot;Positive&quot;, Residual &lt; 0 ~ &quot;Negative&quot;) ) %&gt;% ggplot() + geom_point(aes(x=TeamFGPCT, y=TeamScore, color=Label)) + geom_smooth(aes(x=TeamFGPCT, y=TeamScore), method=&quot;lm&quot;, se=FALSE) ## `geom_smooth()` using formula &#39;y ~ x&#39; Residuals, aside from telling us who is and isn’t playing well, can tell us if a linear model is appropriate for this data. We can use a scatterplot to reveal this. trainresults %&gt;% mutate(Residual = TeamScore - .pred) %&gt;% ggplot() + geom_point(aes(x=TeamFGPCT, y=Residual)) What we’re looking for is for the dots to be randomly spaced around the plot. It should look like someone spilled Skittles on the floor. This … does. It means a linear model is appropriate here. More on that in the coming chapters. 2.3 Predicting data we haven’t seen before Now we can do the same thing, but with the test data. testresults &lt;- game_test %&gt;% bind_cols(predict(fit_lm, game_test)) What do these metrics look like? metrics(testresults, truth = TeamScore, estimate = .pred) ## # A tibble: 3 x 3 ## .metric .estimator .estimate ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 rmse standard 9.23 ## 2 rsq standard 0.501 ## 3 mae standard 7.21 If you look at the r-squared value, you’ll note that when we apply the same model to our test data, the amount of variance that we can explain goes down a little. It’s not much, so the model does a decent job of predicting data we haven’t seen before, which is the whole point of creating a model. 2.4 Looking locally We can get clearer picture of what these predictions look like if we look at something we know – like this season’s Nebraska team. What does the model say about how they are doing? First, we can get Nebraska’s games with a filter. nu &lt;- games %&gt;% filter(Season == &quot;2020-2021&quot;, Team == &quot;Nebraska&quot;) nu ## # A tibble: 12 x 48 ## Season Game Date TeamFull Opponent HomeAway W_L TeamScore ## &lt;chr&gt; &lt;dbl&gt; &lt;date&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 2020-… 1 2020-11-25 Nebrask… McNeese… &lt;NA&gt; W 102 ## 2 2020-… 2 2020-11-26 Nebrask… Nevada &lt;NA&gt; L 66 ## 3 2020-… 3 2020-11-28 Nebrask… North D… &lt;NA&gt; W 79 ## 4 2020-… 4 2020-12-01 Nebrask… South D… &lt;NA&gt; W 76 ## 5 2020-… 5 2020-12-09 Nebrask… Georgia… &lt;NA&gt; L 64 ## 6 2020-… 6 2020-12-11 Nebrask… Creight… @ L 74 ## 7 2020-… 7 2020-12-17 Nebrask… Doane C… &lt;NA&gt; W 110 ## 8 2020-… 8 2020-12-22 Nebrask… Wiscons… @ L 53 ## 9 2020-… 9 2020-12-25 Nebrask… Michigan &lt;NA&gt; L 69 ## 10 2020-… 10 2020-12-30 Nebrask… Ohio St… @ L 54 ## 11 2020-… 11 2021-01-02 Nebrask… Michiga… &lt;NA&gt; L 77 ## 12 2020-… 12 2021-01-10 Nebrask… Indiana &lt;NA&gt; L 76 ## # … with 40 more variables: OpponentScore &lt;dbl&gt;, TeamFG &lt;dbl&gt;, TeamFGA &lt;dbl&gt;, ## # TeamFGPCT &lt;dbl&gt;, Team3P &lt;dbl&gt;, Team3PA &lt;dbl&gt;, Team3PPCT &lt;dbl&gt;, ## # TeamFT &lt;dbl&gt;, TeamFTA &lt;dbl&gt;, TeamFTPCT &lt;dbl&gt;, TeamOffRebounds &lt;dbl&gt;, ## # TeamTotalRebounds &lt;dbl&gt;, TeamAssists &lt;dbl&gt;, TeamSteals &lt;dbl&gt;, ## # TeamBlocks &lt;dbl&gt;, TeamTurnovers &lt;dbl&gt;, TeamPersonalFouls &lt;dbl&gt;, ## # OpponentFG &lt;dbl&gt;, OpponentFGA &lt;dbl&gt;, OpponentFGPCT &lt;dbl&gt;, Opponent3P &lt;dbl&gt;, ## # Opponent3PA &lt;dbl&gt;, Opponent3PPCT &lt;dbl&gt;, OpponentFT &lt;dbl&gt;, ## # OpponentFTA &lt;dbl&gt;, OpponentFTPCT &lt;dbl&gt;, OpponentOffRebounds &lt;dbl&gt;, ## # OpponentTotalRebounds &lt;dbl&gt;, OpponentAssists &lt;dbl&gt;, OpponentSteals &lt;dbl&gt;, ## # OpponentBlocks &lt;dbl&gt;, OpponentTurnovers &lt;dbl&gt;, OpponentPersonalFouls &lt;dbl&gt;, ## # URL &lt;chr&gt;, Conference &lt;chr&gt;, Team &lt;chr&gt;, TeamSRS &lt;dbl&gt;, TeamSOS &lt;dbl&gt;, ## # OpponentSRS &lt;dbl&gt;, OpponentSOS &lt;dbl&gt; Now apply the model to the games. nupreds &lt;- nu %&gt;% bind_cols(predict(fit_lm, nu)) To really see this clearly, we’ll calculate the residual, then sort by the residual. Where did the model miss the most, for good or bad? nupreds %&gt;% mutate(Residual = TeamScore - .pred) %&gt;% arrange(desc(Residual)) %&gt;% select(Team, Opponent, TeamScore, .pred, Residual) ## # A tibble: 12 x 5 ## Team Opponent TeamScore .pred Residual ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Nebraska Doane College 110 85.9 24.1 ## 2 Nebraska McNeese State 102 79.1 22.9 ## 3 Nebraska Nevada 66 52.6 13.4 ## 4 Nebraska South Dakota 76 66.5 9.51 ## 5 Nebraska North Dakota State 79 74.1 4.93 ## 6 Nebraska Michigan 69 65.4 3.64 ## 7 Nebraska Creighton 74 71.4 2.58 ## 8 Nebraska Indiana 76 73.6 2.44 ## 9 Nebraska Ohio State 54 51.7 2.28 ## 10 Nebraska Georgia Tech 64 63.6 0.411 ## 11 Nebraska Michigan State 77 78.0 -0.982 ## 12 Nebraska Wisconsin 53 58.0 -5.03 What does this mean? It says the model predicted the team would score 86 against Doane and they put up 110, for a 24 point miss (residual). For most games, the prediction is within a few points – it nailed the Georgia Tech game - and we did worse against Wisconsin than the model would have guessed. We underperformed, in a manner of speaking. Linear models are incredibly important to understand — they underpin many of the more advanced methods we’ll talk about going forward — so understanding them now is critical. "],["multiple-regression-and-feature-engineering.html", "Chapter 3 Multiple regression and feature engineering 3.1 A multiple regression speed run 3.2 Picking what moves the needle 3.3 Feature engineering", " Chapter 3 Multiple regression and feature engineering As we saw in the previous chapter, we can measure how much something can be predicted by another thing. We looked at how many points a team can score based on their shooting percentage. The theory being how well you shoot the ball probably has a lot to say about how many points you score. And what did we find? It’s about half the story. But that raises the problem with simple regressions – they’re simple. Anyone who has watched a basketball game knows there’s a lot more to the outcome than just shooting prowess. Enter the multiple regression. Multiple regressions are a step toward reality – where more than one thing influences the outcome. However, the more variance we attempt to explain, the more error and uncertainty we introduce into our model. Let’s begin by loading some libraries and installing a new one: corrr We install it by going to the console and typing install.packages(\"corrr\") library(tidyverse) library(tidymodels) library(corrr) For this, we’ll work with our college basketball game data and we’ll continue down the road we started in the last chapter. For this walkthrough: Download csv file Let’s import the data. games &lt;- read_csv(&quot;data/cbblogs1521.csv&quot;) ## ## ── Column specification ──────────────────────────────────────────────────────── ## cols( ## .default = col_double(), ## Season = col_character(), ## Date = col_date(format = &quot;&quot;), ## TeamFull = col_character(), ## Opponent = col_character(), ## HomeAway = col_character(), ## W_L = col_character(), ## URL = col_character(), ## Conference = col_character(), ## Team = col_character() ## ) ## ℹ Use `spec()` for the full column specifications. 3.1 A multiple regression speed run First, let’s restore what we did in last chapter, spitting our data into training and testing, creating a linear model predicting score from the shooting percentage and producing the metrics for the results. set.seed(1234) game_split &lt;- initial_split(games, prop = .8) game_train &lt;- training(game_split) game_test &lt;- testing(game_split) lm_model &lt;- linear_reg() %&gt;% set_engine(&quot;lm&quot;) fit_lm &lt;- lm_model %&gt;% fit(TeamScore ~ TeamFGPCT, data = game_train) trainresults &lt;- game_train %&gt;% bind_cols(predict(fit_lm, game_train)) metrics(trainresults, truth = TeamScore, estimate = .pred) ## # A tibble: 3 x 3 ## .metric .estimator .estimate ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 rmse standard 9.34 ## 2 rsq standard 0.506 ## 3 mae standard 7.27 Bottom line: We can predict about 50 percent of the difference in team scores by the shooting percentage. But we know, because we’ve shot hoops in the driveway before, or went through a basketball unit in PE in the third grade, that sure, being a good shooter is important, but how many times you shoot the ball is also important. If you’re a 100 percent shooter, that’s insane, but it probably means you took one shot. Congrats, you scored two points (three if you’re gutsy). One shot is not going to win a game. It would make sense, then, that we should combine the number of shots taken with the shooting percentage to predict the score. Doing that could not be easier. It’s literally adding + TeamFGA to your fit function. Now our model says TeamScore is approximately modeled by how well a team shoots the ball and how many shots they take. fit_lm &lt;- lm_model %&gt;% fit(TeamScore ~ TeamFGPCT + TeamFGA, data = game_train) trainresults &lt;- game_train %&gt;% bind_cols(predict(fit_lm, game_train)) metrics(trainresults, truth = TeamScore, estimate = .pred) ## # A tibble: 3 x 3 ## .metric .estimator .estimate ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 rmse standard 6.46 ## 2 rsq standard 0.763 ## 3 mae standard 5.15 And just like that, by acknowledging reality, we’ve jumped to 76 percent of variance explained and our root mean squared error – the average amount we’re off by – has dropped from 9.3 to 6.5. Your temptation now is to start adding things until we get to 1 on the r-squared and 0 on the rmse. The problem with that is called “overfitting” Overfitting is where you produce a model that is too close to your training data, which makes it prone to fail with data you’ve never seen before – the model becomes unreliable when it’s not the training data anymore. A secondary problem you encounter is this: the point of this is to predict future events. In this class, we’re attempting to predict the outcome of things that have not yet happened. That means we are going to be estimating the inputs to these models, inputs that will no doubt have error. So our inputs have a range of possible outcomes, our model is not perfect, so the outcome is going to combine the two. The more elements of your model that you use as inputs, the more error – uncertainty – you are introducing. The point is you want to pick the things that really matter and ignore the rest in some vain quest to get to 100 percent. You won’t get there. 3.2 Picking what moves the needle There are multiple ways to find the right combination of inputs to your models. With multiple regressions, the most common is the correlation matrix. We’re looking to maximize r-squared by choosing inputs that are highly correlated to our target value, but not correlated with other things. Example: We can assume that TeamFG and TeamFGPCT are highly correlated to TeamScore, but the number of Field Goals made is also highly correlated with the field goal percentage. Using corrr, we can create a correlation matrix in a dataframe and use filter to find columns that are highly correlated with our target – team score. To do this, we need to drop all non-numeric data, then we need to dump one numeric variable that isn’t really a number - the game number of the season. To narrow in a bit, we’ll select just two columns to get a view of things, which we will have to expand upon soon. games %&gt;% select_if(is.numeric) %&gt;% select(-Game) %&gt;% correlate() %&gt;% filter(TeamScore &gt; .4) %&gt;% select(term, TeamScore) ## # A tibble: 7 x 2 ## term TeamScore ## &lt;chr&gt; &lt;dbl&gt; ## 1 TeamFG 0.875 ## 2 TeamFGA 0.436 ## 3 TeamFGPCT 0.710 ## 4 Team3P 0.512 ## 5 Team3PPCT 0.471 ## 6 TeamFT 0.418 ## 7 TeamAssists 0.639 By this, there’s seven things correlated with TeamScore at a greater than .4 level. However, this is half the story. The issue becomes how correlated are those things to each other. To see that, we need to fix our select: games %&gt;% select_if(is.numeric) %&gt;% select(-Game) %&gt;% correlate() %&gt;% filter(TeamScore &gt; .4) %&gt;% select(term, TeamScore, TeamFG, TeamFGA, TeamFGPCT, Team3P, Team3PPCT, TeamFT, TeamAssists) ## # A tibble: 7 x 9 ## term TeamScore TeamFG TeamFGA TeamFGPCT Team3P Team3PPCT TeamFT ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Team… 0.875 NA 0.566 0.757 0.407 0.380 -0.0180 ## 2 Team… 0.436 0.566 NA -0.0971 0.219 -0.0940 -0.133 ## 3 Team… 0.710 0.757 -0.0971 NA 0.320 0.541 0.0842 ## 4 Team… 0.512 0.407 0.219 0.320 NA 0.709 -0.101 ## 5 Team… 0.471 0.380 -0.0940 0.541 0.709 NA 0.00913 ## 6 Team… 0.418 -0.0180 -0.133 0.0842 -0.101 0.00913 NA ## 7 Team… 0.639 0.663 0.293 0.563 0.526 0.433 -0.0160 ## # … with 1 more variable: TeamAssists &lt;dbl&gt; Reading this can be a lot, and it helps to take some notes as you go. TeamFG is the most correlated to TeamScore – which makes sense. Made shots are points. But they’re also highly correlated to attempts and even more to percentage. There’s others that it’s highly correlated with. Attempts are moderately associated with TeamScore, but notice they are NOT correlated with TeamFGPCT. What does that tell you? It says teams shoot the ball, regardless of how good they are at it, and the two aren’t related to each other BUT they are related to the points teams score. Perfect. 3.3 Feature engineering Feature engineering is the process of using what you know about something – domain knowledge – to find features in data that can be used in machine learning algorithms. Sports is a great place for this because not only do we know a lot because we follow the sport, but lots of other people are looking at this all the time. Creativity is good. Let’s look at basketball games again. A number of basketball heads – including Ken Pomeroy of KenPom fame – have noticed that one of the predictors of the outcome of basketball games are possession metrics. How efficient are teams with the possessions they have? Can’t score if you don’t have the ball, so how good is a team at pushing the play and getting more possessions, giving themselves more chances to score? One problem? Possessions aren’t in typical metrics. They aren’t usually tracked. But you can estimate them from typical box scores. The way to do that is like this: Possessions = Field Goal Attempts – Offensive Rebounds + Turnovers + (0.475 * Free Throw Attempts) Here is that formula applied to our data, plus creating some new metrics of Points Per Possession for both Team and Opponent: gameswithpossessions &lt;- games %&gt;% mutate( TeamPossessions = TeamFGA - TeamOffRebounds + TeamTurnovers + (.475 * TeamFTA), OpponentPossessions = OpponentFGA - OpponentOffRebounds + OpponentTurnovers + (.475 * OpponentFTA), TeamPPP = TeamScore/TeamPossessions, OpponentPPP = OpponentScore/OpponentPossessions) Now lets look at the correlation matrix for our newly added data: gameswithpossessions %&gt;% select_if(is.numeric) %&gt;% select(-Game) %&gt;% correlate() %&gt;% filter(TeamScore &gt; .4) %&gt;% select(term, TeamScore) ## # A tibble: 10 x 2 ## term TeamScore ## &lt;chr&gt; &lt;dbl&gt; ## 1 TeamFG 0.875 ## 2 TeamFGA 0.436 ## 3 TeamFGPCT 0.710 ## 4 Team3P 0.512 ## 5 Team3PPCT 0.471 ## 6 TeamFT 0.418 ## 7 TeamAssists 0.639 ## 8 TeamPossessions 0.536 ## 9 OpponentPossessions 0.557 ## 10 TeamPPP 0.850 Note: our new possession metrics now make the grade here. But are they correlated with each other? gameswithpossessions %&gt;% select_if(is.numeric) %&gt;% select(-Game) %&gt;% correlate() %&gt;% filter(TeamScore &gt; .4) %&gt;% select(term, TeamScore, TeamFG, TeamFGA, TeamFGPCT, Team3P, Team3PPCT, TeamFT, TeamAssists, TeamPossessions, OpponentPossessions, TeamPPP) ## # A tibble: 10 x 12 ## term TeamScore TeamFG TeamFGA TeamFGPCT Team3P Team3PPCT TeamFT ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Team… 0.875 NA 0.566 0.757 0.407 0.380 -0.0180 ## 2 Team… 0.436 0.566 NA -0.0971 0.219 -0.0940 -0.133 ## 3 Team… 0.710 0.757 -0.0971 NA 0.320 0.541 0.0842 ## 4 Team… 0.512 0.407 0.219 0.320 NA 0.709 -0.101 ## 5 Team… 0.471 0.380 -0.0940 0.541 0.709 NA 0.00913 ## 6 Team… 0.418 -0.0180 -0.133 0.0842 -0.101 0.00913 NA ## 7 Team… 0.639 0.663 0.293 0.563 0.526 0.433 -0.0160 ## 8 Team… 0.536 0.443 0.615 0.0534 0.146 -0.0217 0.335 ## 9 Oppo… 0.557 0.453 0.538 0.125 0.173 0.0321 0.352 ## 10 Team… 0.850 0.757 0.135 0.810 0.516 0.576 0.289 ## # … with 4 more variables: TeamAssists &lt;dbl&gt;, TeamPossessions &lt;dbl&gt;, ## # OpponentPossessions &lt;dbl&gt;, TeamPPP &lt;dbl&gt; Let’s look specifically at our TeamPPP and TeamPossessions metrics. Both are correlated to TeamScore – TeamPPP is highly correlated – but they AREN’T very correlated to each other. If you think about it, it makes some sense: one is a measure of how good the team is at getting the ball into their hands, the other is a measure of how efficient they are at scoring when they have the ball. Both metrics encompass a lot about a game – steals, rebounds, free throws, etc. – that basic shooting metrics don’t give you. So how does this look in a model? First, there’s a very small number of games with blanks for some of shooting stats, so we need to dump them first or we’ll get errors. gameswithpossessions &lt;- gameswithpossessions %&gt;% filter(TeamFGPCT&gt;0, OpponentFGPCT&gt;0) First we split our data into training and testing. newgame_split &lt;- initial_split(gameswithpossessions, prop = .8) newgame_train &lt;- training(newgame_split) newgame_test &lt;- testing(newgame_split) Create the model shell. lm_model &lt;- linear_reg() %&gt;% set_engine(&quot;lm&quot;) Create the fit. fit_lm &lt;- lm_model %&gt;% fit(TeamScore ~ TeamPossessions + TeamPPP, data = newgame_train) Let’s take a peek at our model coefficients. tidy(fit_lm, conf.int = TRUE) ## # A tibble: 3 x 7 ## term estimate std.error statistic p.value conf.low conf.high ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) -72.2 0.0607 -1188. 0 -72.3 -72.0 ## 2 TeamPossessions 1.02 0.000736 1389. 0 1.02 1.02 ## 3 TeamPPP 70.6 0.0316 2233. 0 70.6 70.7 What this says is if we have zero possessions in a basketball game, we’ll score -72 points. Well, we know neither are possible, so we ignore that. The model says for each possession, we should score about 1.02 points, and if we were to score 1 point per possession, we’d score 70.6 points. Now we play the games. trainresults &lt;- newgame_train %&gt;% bind_cols(predict(fit_lm, newgame_train)) metrics(trainresults, truth = TeamScore, estimate = .pred) ## # A tibble: 3 x 3 ## .metric .estimator .estimate ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 rmse standard 1.09 ## 2 rsq standard 0.993 ## 3 mae standard 0.661 So … knowing possession metrics makes you VERY good at predicting the total points a team will score. That’s frighteningly high — overfitting high. But we’ll continue to test it out. How well does the model do with data it hasn’t seen before? testresults &lt;- newgame_test %&gt;% bind_cols(predict(fit_lm, newgame_test)) metrics(testresults, truth = TeamScore, estimate = .pred) ## # A tibble: 3 x 3 ## .metric .estimator .estimate ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 rmse standard 1.07 ## 2 rsq standard 0.993 ## 3 mae standard 0.662 Again … somewhat terrifyingly well. Let’s put this against a set of games we’re familiar with. nu &lt;- gameswithpossessions %&gt;% filter(Season == &quot;2020-2021&quot;, TeamFull == &quot;Nebraska Cornhuskers&quot;) nupreds &lt;- nu %&gt;% bind_cols(predict(fit_lm, nu)) nupreds %&gt;% mutate(Residual = TeamScore - .pred) %&gt;% arrange(desc(Residual)) %&gt;% select(Team, Opponent, TeamScore, .pred, Residual) ## # A tibble: 12 x 5 ## Team Opponent TeamScore .pred Residual ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Nebraska Doane College 110 107. 3.45 ## 2 Nebraska McNeese State 102 99.6 2.43 ## 3 Nebraska Wisconsin 53 52.0 0.981 ## 4 Nebraska North Dakota State 79 78.9 0.110 ## 5 Nebraska Michigan State 77 76.9 0.0603 ## 6 Nebraska Indiana 76 76.0 0.0317 ## 7 Nebraska Georgia Tech 64 64.1 -0.0799 ## 8 Nebraska Michigan 69 69.5 -0.546 ## 9 Nebraska South Dakota 76 76.6 -0.562 ## 10 Nebraska Nevada 66 66.7 -0.689 ## 11 Nebraska Creighton 74 75.8 -1.75 ## 12 Nebraska Ohio State 54 56.1 -2.06 Our multiple regression model does the worst with blowouts, but it’s within a point on most games. The question to start thinking about is this – how well can you predict the number of possessions a team will have going into a game, and how many points they’ll score on each of those possessions? "],["decision-trees-and-random-forests.html", "Chapter 4 Decision trees and random forests 4.1 An intro to pre-processsing 4.2 Using our possession metrics", " Chapter 4 Decision trees and random forests Tree-based algorithms are based on decision trees, which are very easy to understand. A decision tree can basically be described as a series of questions. Does this player have more or less seasons of experience? Do they have more or less minutes played? Do they play this or that position? Answer enough questions, and you can predict what that player should have. The trouble with decision trees is that they’re a bit of a crude instrument. As such, multiple tree based methods have been developed as improvements on the humble decision tree. The most common is the random forest. library(tidyverse) library(tidymodels) For this walkthrough: Download csv file Let’s load this data and take a look at it. games &lt;- read_csv(&quot;data/cbblogs1521.csv&quot;) ## ## ── Column specification ──────────────────────────────────────────────────────── ## cols( ## .default = col_double(), ## Season = col_character(), ## Date = col_date(format = &quot;&quot;), ## TeamFull = col_character(), ## Opponent = col_character(), ## HomeAway = col_character(), ## W_L = col_character(), ## URL = col_character(), ## Conference = col_character(), ## Team = col_character() ## ) ## ℹ Use `spec()` for the full column specifications. 4.1 An intro to pre-processsing games &lt;- games %&gt;% filter(TeamFGPCT &gt; 0) set.seed(1234) game_split &lt;- initial_split(games, prop = .8) game_train &lt;- training(game_split) game_test &lt;- testing(game_split) rf_mod &lt;- rand_forest() %&gt;% set_engine(&quot;randomForest&quot;) %&gt;% set_mode(&quot;regression&quot;) This step takes more than a minute to run on a fairly new laptop, so be warned. fit_rf &lt;- rf_mod %&gt;% fit(TeamScore ~ TeamFGPCT, data = game_train) trainresults &lt;- game_train %&gt;% bind_cols(predict(fit_rf, game_train)) metrics(trainresults, truth = TeamScore, estimate = .pred) ## # A tibble: 3 x 3 ## .metric .estimator .estimate ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 rmse standard 8.68 ## 2 rsq standard 0.571 ## 3 mae standard 6.67 testresults &lt;- game_test %&gt;% bind_cols(predict(fit_rf, game_test)) metrics(testresults, truth = TeamScore, estimate = .pred) ## # A tibble: 3 x 3 ## .metric .estimator .estimate ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 rmse standard 8.64 ## 2 rsq standard 0.564 ## 3 mae standard 6.63 nu &lt;- games %&gt;% filter(Season == &quot;2020-2021&quot;, Team == &quot;Nebraska&quot;) nu ## # A tibble: 12 x 48 ## Season Game Date TeamFull Opponent HomeAway W_L TeamScore ## &lt;chr&gt; &lt;dbl&gt; &lt;date&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 2020-… 1 2020-11-25 Nebrask… McNeese… &lt;NA&gt; W 102 ## 2 2020-… 2 2020-11-26 Nebrask… Nevada &lt;NA&gt; L 66 ## 3 2020-… 3 2020-11-28 Nebrask… North D… &lt;NA&gt; W 79 ## 4 2020-… 4 2020-12-01 Nebrask… South D… &lt;NA&gt; W 76 ## 5 2020-… 5 2020-12-09 Nebrask… Georgia… &lt;NA&gt; L 64 ## 6 2020-… 6 2020-12-11 Nebrask… Creight… @ L 74 ## 7 2020-… 7 2020-12-17 Nebrask… Doane C… &lt;NA&gt; W 110 ## 8 2020-… 8 2020-12-22 Nebrask… Wiscons… @ L 53 ## 9 2020-… 9 2020-12-25 Nebrask… Michigan &lt;NA&gt; L 69 ## 10 2020-… 10 2020-12-30 Nebrask… Ohio St… @ L 54 ## 11 2020-… 11 2021-01-02 Nebrask… Michiga… &lt;NA&gt; L 77 ## 12 2020-… 12 2021-01-10 Nebrask… Indiana &lt;NA&gt; L 76 ## # … with 40 more variables: OpponentScore &lt;dbl&gt;, TeamFG &lt;dbl&gt;, TeamFGA &lt;dbl&gt;, ## # TeamFGPCT &lt;dbl&gt;, Team3P &lt;dbl&gt;, Team3PA &lt;dbl&gt;, Team3PPCT &lt;dbl&gt;, ## # TeamFT &lt;dbl&gt;, TeamFTA &lt;dbl&gt;, TeamFTPCT &lt;dbl&gt;, TeamOffRebounds &lt;dbl&gt;, ## # TeamTotalRebounds &lt;dbl&gt;, TeamAssists &lt;dbl&gt;, TeamSteals &lt;dbl&gt;, ## # TeamBlocks &lt;dbl&gt;, TeamTurnovers &lt;dbl&gt;, TeamPersonalFouls &lt;dbl&gt;, ## # OpponentFG &lt;dbl&gt;, OpponentFGA &lt;dbl&gt;, OpponentFGPCT &lt;dbl&gt;, Opponent3P &lt;dbl&gt;, ## # Opponent3PA &lt;dbl&gt;, Opponent3PPCT &lt;dbl&gt;, OpponentFT &lt;dbl&gt;, ## # OpponentFTA &lt;dbl&gt;, OpponentFTPCT &lt;dbl&gt;, OpponentOffRebounds &lt;dbl&gt;, ## # OpponentTotalRebounds &lt;dbl&gt;, OpponentAssists &lt;dbl&gt;, OpponentSteals &lt;dbl&gt;, ## # OpponentBlocks &lt;dbl&gt;, OpponentTurnovers &lt;dbl&gt;, OpponentPersonalFouls &lt;dbl&gt;, ## # URL &lt;chr&gt;, Conference &lt;chr&gt;, Team &lt;chr&gt;, TeamSRS &lt;dbl&gt;, TeamSOS &lt;dbl&gt;, ## # OpponentSRS &lt;dbl&gt;, OpponentSOS &lt;dbl&gt; nupreds &lt;- nu %&gt;% bind_cols(predict(fit_rf, nu)) nupreds %&gt;% mutate(Residual = TeamScore - .pred) %&gt;% arrange(desc(Residual)) %&gt;% select(Team, Opponent, TeamScore, .pred, Residual) ## # A tibble: 12 x 5 ## Team Opponent TeamScore .pred Residual ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Nebraska McNeese State 102 78.0 24.0 ## 2 Nebraska Doane College 110 88.4 21.6 ## 3 Nebraska Nevada 66 55.6 10.4 ## 4 Nebraska South Dakota 76 66.8 9.24 ## 5 Nebraska North Dakota State 79 73.0 5.98 ## 6 Nebraska Ohio State 54 49.0 5.03 ## 7 Nebraska Michigan 69 67.1 1.86 ## 8 Nebraska Michigan State 77 75.6 1.41 ## 9 Nebraska Creighton 74 72.6 1.36 ## 10 Nebraska Indiana 76 74.7 1.34 ## 11 Nebraska Georgia Tech 64 64.1 -0.0843 ## 12 Nebraska Wisconsin 53 56.6 -3.63 4.2 Using our possession metrics gameswithpossessions &lt;- games %&gt;% mutate( TeamPossessions = TeamFGA - TeamOffRebounds + TeamTurnovers + (.475 * TeamFTA), OpponentPossessions = OpponentFGA - OpponentOffRebounds + OpponentTurnovers + (.475 * OpponentFTA), TeamPPP = TeamScore/TeamPossessions, OpponentPPP = OpponentScore/OpponentPossessions) newgame_split &lt;- initial_split(gameswithpossessions, prop = .8) newgame_train &lt;- training(newgame_split) newgame_test &lt;- testing(newgame_split) fit_rf &lt;- rf_mod %&gt;% fit(TeamScore ~ TeamPossessions + TeamPPP, data = newgame_train) trainresults &lt;- newgame_train %&gt;% bind_cols(predict(fit_rf, newgame_train)) metrics(trainresults, truth = TeamScore, estimate = .pred) ## # A tibble: 3 x 3 ## .metric .estimator .estimate ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 rmse standard 0.196 ## 2 rsq standard 1.00 ## 3 mae standard 0.0561 "],["xgboost.html", "Chapter 5 XGBoost", " Chapter 5 XGBoost To come. "],["support-vector-machines.html", "Chapter 6 Support Vector Machines", " Chapter 6 Support Vector Machines To come. "]]
