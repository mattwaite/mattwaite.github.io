<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 Multiple regression | Advanced Sports Data Analysis</title>
  <meta name="description" content="This is the companion text to the University of Nebraska-Lincoln’s SPMC 460: Advanced Sports Data Analysis" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 Multiple regression | Advanced Sports Data Analysis" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is the companion text to the University of Nebraska-Lincoln’s SPMC 460: Advanced Sports Data Analysis" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 Multiple regression | Advanced Sports Data Analysis" />
  
  <meta name="twitter:description" content="This is the companion text to the University of Nebraska-Lincoln’s SPMC 460: Advanced Sports Data Analysis" />
  

<meta name="author" content="By Matt Waite" />


<meta name="date" content="2022-02-17" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="the-modeling-process-and-linear-regression.html"/>
<link rel="next" href="decision-trees-and-random-forests.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  background-color: #f8f8f8; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Advanced Sports Data Analysis</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#requirements-and-conventions"><i class="fa fa-check"></i><b>1.1</b> Requirements and Conventions</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#about-this-book"><i class="fa fa-check"></i><b>1.2</b> About this book</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="the-modeling-process-and-linear-regression.html"><a href="the-modeling-process-and-linear-regression.html"><i class="fa fa-check"></i><b>2</b> The modeling process and linear regression</a>
<ul>
<li class="chapter" data-level="2.1" data-path="the-modeling-process-and-linear-regression.html"><a href="the-modeling-process-and-linear-regression.html#feature-engineering"><i class="fa fa-check"></i><b>2.1</b> Feature engineering</a></li>
<li class="chapter" data-level="2.2" data-path="the-modeling-process-and-linear-regression.html"><a href="the-modeling-process-and-linear-regression.html#setting-up-the-modeling-process"><i class="fa fa-check"></i><b>2.2</b> Setting up the modeling process</a></li>
<li class="chapter" data-level="2.3" data-path="the-modeling-process-and-linear-regression.html"><a href="the-modeling-process-and-linear-regression.html#predicting-based-on-the-model"><i class="fa fa-check"></i><b>2.3</b> Predicting based on the model</a></li>
<li class="chapter" data-level="2.4" data-path="the-modeling-process-and-linear-regression.html"><a href="the-modeling-process-and-linear-regression.html#predicting-data-we-havent-seen-before"><i class="fa fa-check"></i><b>2.4</b> Predicting data we haven’t seen before</a></li>
<li class="chapter" data-level="2.5" data-path="the-modeling-process-and-linear-regression.html"><a href="the-modeling-process-and-linear-regression.html#looking-locally"><i class="fa fa-check"></i><b>2.5</b> Looking locally</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="multiple-regression.html"><a href="multiple-regression.html"><i class="fa fa-check"></i><b>3</b> Multiple regression</a>
<ul>
<li class="chapter" data-level="3.1" data-path="multiple-regression.html"><a href="multiple-regression.html#a-multiple-regression-speed-run"><i class="fa fa-check"></i><b>3.1</b> A multiple regression speed run</a></li>
<li class="chapter" data-level="3.2" data-path="multiple-regression.html"><a href="multiple-regression.html#picking-what-moves-the-needle"><i class="fa fa-check"></i><b>3.2</b> Picking what moves the needle</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="decision-trees-and-random-forests.html"><a href="decision-trees-and-random-forests.html"><i class="fa fa-check"></i><b>4</b> Decision trees and random forests</a>
<ul>
<li class="chapter" data-level="4.1" data-path="decision-trees-and-random-forests.html"><a href="decision-trees-and-random-forests.html#an-intro-to-pre-processing"><i class="fa fa-check"></i><b>4.1</b> An intro to pre-processing</a></li>
<li class="chapter" data-level="4.2" data-path="decision-trees-and-random-forests.html"><a href="decision-trees-and-random-forests.html#decision-trees"><i class="fa fa-check"></i><b>4.2</b> Decision trees</a></li>
<li class="chapter" data-level="4.3" data-path="decision-trees-and-random-forests.html"><a href="decision-trees-and-random-forests.html#random-forest"><i class="fa fa-check"></i><b>4.3</b> Random forest</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="xgboost.html"><a href="xgboost.html"><i class="fa fa-check"></i><b>5</b> XGBoost</a>
<ul>
<li class="chapter" data-level="5.1" data-path="xgboost.html"><a href="xgboost.html#hyperparameters"><i class="fa fa-check"></i><b>5.1</b> Hyperparameters</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>6</b> Logistic Regression</a>
<ul>
<li class="chapter" data-level="6.1" data-path="logistic-regression.html"><a href="logistic-regression.html#visualizing-the-decision-boundary"><i class="fa fa-check"></i><b>6.1</b> Visualizing the decision boundary</a></li>
<li class="chapter" data-level="6.2" data-path="logistic-regression.html"><a href="logistic-regression.html#the-logistic-regression"><i class="fa fa-check"></i><b>6.2</b> The logistic regression</a></li>
<li class="chapter" data-level="6.3" data-path="logistic-regression.html"><a href="logistic-regression.html#evaluating-the-fit"><i class="fa fa-check"></i><b>6.3</b> Evaluating the fit</a></li>
<li class="chapter" data-level="6.4" data-path="logistic-regression.html"><a href="logistic-regression.html#comparing-it-to-test-data"><i class="fa fa-check"></i><b>6.4</b> Comparing it to test data</a></li>
<li class="chapter" data-level="6.5" data-path="logistic-regression.html"><a href="logistic-regression.html#how-well-did-it-do-with-nebraska"><i class="fa fa-check"></i><b>6.5</b> How well did it do with Nebraska?</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Advanced Sports Data Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="multiple-regression" class="section level1" number="3">
<h1><span class="header-section-number">Chapter 3</span> Multiple regression</h1>
<p>As we saw in the previous chapter, we can measure how much something can be predicted by another thing. We looked at how many points a team can score based on their shooting percentage. The theory being how well you shoot the ball probably has a lot to say about how many points you score. And what did we find? It’s a part of the story, but not the whole story.</p>
<p>But that raises the problem with simple regressions – they’re simple. Anyone who has watched a basketball game knows there’s a lot more to the outcome than just shooting prowess.</p>
<p>Enter the multiple regression.</p>
<p>Multiple regressions are a step toward reality – where more than one thing influences the outcome. However, the more variance we attempt to explain, the more error and uncertainty we introduce into our model.</p>
<p>Let’s begin by loading some libraries and installing a new one: <code>corrr</code></p>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="multiple-regression.html#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb37-2"><a href="multiple-regression.html#cb37-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidymodels)</span>
<span id="cb37-3"><a href="multiple-regression.html#cb37-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(zoo)</span>
<span id="cb37-4"><a href="multiple-regression.html#cb37-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(hoopR)</span>
<span id="cb37-5"><a href="multiple-regression.html#cb37-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(corrr)</span></code></pre></div>
<p>For this, we’ll work with our college basketball game data and we’ll continue down the road we started in the last chapter.</p>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="multiple-regression.html#cb38-1" aria-hidden="true" tabindex="-1"></a>teamgames <span class="ot">&lt;-</span> <span class="fu">load_mbb_team_box</span>(<span class="at">seasons =</span> <span class="dv">2015</span><span class="sc">:</span><span class="dv">2022</span>) <span class="sc">%&gt;%</span></span>
<span id="cb38-2"><a href="multiple-regression.html#cb38-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">separate</span>(field_goals_made_field_goals_attempted, <span class="at">into =</span> <span class="fu">c</span>(<span class="st">&quot;field_goals_made&quot;</span>,<span class="st">&quot;field_goals_attempted&quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb38-3"><a href="multiple-regression.html#cb38-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">separate</span>(three_point_field_goals_made_three_point_field_goals_attempted, <span class="at">into =</span> <span class="fu">c</span>(<span class="st">&quot;three_point_field_goals_made&quot;</span>,<span class="st">&quot;three_point_field_goals_attempted&quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb38-4"><a href="multiple-regression.html#cb38-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">separate</span>(free_throws_made_free_throws_attempted, <span class="at">into =</span> <span class="fu">c</span>(<span class="st">&quot;free_throws_made&quot;</span>,<span class="st">&quot;free_throws_attempted&quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb38-5"><a href="multiple-regression.html#cb38-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate_at</span>(<span class="dv">12</span><span class="sc">:</span><span class="dv">35</span>, as.numeric)</span></code></pre></div>
<pre><code>## Warning in mask$eval_all_mutate(quo): NAs introduced by coercion</code></pre>
<div id="a-multiple-regression-speed-run" class="section level2" number="3.1">
<h2><span class="header-section-number">3.1</span> A multiple regression speed run</h2>
<p>First, let’s restore what we did in last chapter with the feature engineering we did, making the different metrics and the rolling numbers.</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb40-1"><a href="multiple-regression.html#cb40-1" aria-hidden="true" tabindex="-1"></a>teamstats <span class="ot">&lt;-</span> teamgames <span class="sc">%&gt;%</span> </span>
<span id="cb40-2"><a href="multiple-regression.html#cb40-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(team_short_display_name) <span class="sc">%&gt;%</span></span>
<span id="cb40-3"><a href="multiple-regression.html#cb40-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb40-4"><a href="multiple-regression.html#cb40-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">team_score =</span> ((field_goals_made<span class="sc">-</span>three_point_field_goals_made) <span class="sc">*</span> <span class="dv">2</span>) <span class="sc">+</span> (three_point_field_goals_made<span class="sc">*</span><span class="dv">3</span>) <span class="sc">+</span> free_throws_made,</span>
<span id="cb40-5"><a href="multiple-regression.html#cb40-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">possessions =</span> field_goals_attempted <span class="sc">-</span> offensive_rebounds <span class="sc">+</span> turnovers <span class="sc">+</span> (.<span class="dv">475</span> <span class="sc">*</span> free_throws_attempted),</span>
<span id="cb40-6"><a href="multiple-regression.html#cb40-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">ppp =</span> team_score<span class="sc">/</span>possessions,</span>
<span id="cb40-7"><a href="multiple-regression.html#cb40-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">true_shooting_percentage =</span> (team_score <span class="sc">/</span> (<span class="dv">2</span><span class="sc">*</span>(field_goals_attempted <span class="sc">+</span> (.<span class="dv">44</span> <span class="sc">*</span> free_throws_attempted)))) <span class="sc">*</span> <span class="dv">100</span>,</span>
<span id="cb40-8"><a href="multiple-regression.html#cb40-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">rolling_shooting_percentage =</span> <span class="fu">rollmean</span>(<span class="fu">lag</span>(field_goal_pct, <span class="at">n=</span><span class="dv">1</span>), <span class="at">k=</span><span class="dv">2</span>, <span class="at">fill=</span>field_goal_pct),</span>
<span id="cb40-9"><a href="multiple-regression.html#cb40-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">rolling_ppp =</span> <span class="fu">rollmean</span>(<span class="fu">lag</span>(ppp, <span class="at">n=</span><span class="dv">1</span>), <span class="at">k=</span><span class="dv">2</span>, <span class="at">fill=</span>ppp),</span>
<span id="cb40-10"><a href="multiple-regression.html#cb40-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">rolling_true_shooting_percentage =</span> <span class="fu">rollmean</span>(<span class="fu">lag</span>(true_shooting_percentage, <span class="at">n=</span><span class="dv">1</span>), <span class="at">k=</span><span class="dv">2</span>, <span class="at">fill=</span>true_shooting_percentage)</span>
<span id="cb40-11"><a href="multiple-regression.html#cb40-11" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> <span class="fu">ungroup</span>()</span></code></pre></div>
<p>Now we’ll split our data into training and testing, creating a linear model predicting score from the shooting percentage and producing the metrics for the results.</p>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="multiple-regression.html#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb41-2"><a href="multiple-regression.html#cb41-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-3"><a href="multiple-regression.html#cb41-3" aria-hidden="true" tabindex="-1"></a>game_split <span class="ot">&lt;-</span> <span class="fu">initial_split</span>(teamstats, <span class="at">prop =</span> .<span class="dv">8</span>)</span>
<span id="cb41-4"><a href="multiple-regression.html#cb41-4" aria-hidden="true" tabindex="-1"></a>game_train <span class="ot">&lt;-</span> <span class="fu">training</span>(game_split)</span>
<span id="cb41-5"><a href="multiple-regression.html#cb41-5" aria-hidden="true" tabindex="-1"></a>game_test <span class="ot">&lt;-</span> <span class="fu">testing</span>(game_split)</span>
<span id="cb41-6"><a href="multiple-regression.html#cb41-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-7"><a href="multiple-regression.html#cb41-7" aria-hidden="true" tabindex="-1"></a>lm_model <span class="ot">&lt;-</span> <span class="fu">linear_reg</span>() <span class="sc">%&gt;%</span></span>
<span id="cb41-8"><a href="multiple-regression.html#cb41-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">set_engine</span>(<span class="st">&quot;lm&quot;</span>)</span>
<span id="cb41-9"><a href="multiple-regression.html#cb41-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-10"><a href="multiple-regression.html#cb41-10" aria-hidden="true" tabindex="-1"></a>fit_lm <span class="ot">&lt;-</span> lm_model <span class="sc">%&gt;%</span></span>
<span id="cb41-11"><a href="multiple-regression.html#cb41-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(team_score <span class="sc">~</span> rolling_shooting_percentage, <span class="at">data =</span> game_train)</span>
<span id="cb41-12"><a href="multiple-regression.html#cb41-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-13"><a href="multiple-regression.html#cb41-13" aria-hidden="true" tabindex="-1"></a>trainresults <span class="ot">&lt;-</span> game_train <span class="sc">%&gt;%</span></span>
<span id="cb41-14"><a href="multiple-regression.html#cb41-14" aria-hidden="true" tabindex="-1"></a>    <span class="fu">bind_cols</span>(<span class="fu">predict</span>(fit_lm, game_train))</span>
<span id="cb41-15"><a href="multiple-regression.html#cb41-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-16"><a href="multiple-regression.html#cb41-16" aria-hidden="true" tabindex="-1"></a><span class="fu">metrics</span>(trainresults, <span class="at">truth =</span> team_score, <span class="at">estimate =</span> .pred)</span></code></pre></div>
<pre><code>## # A tibble: 3 × 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 rmse    standard      11.0  
## 2 rsq     standard       0.321
## 3 mae     standard       8.63</code></pre>
<p>Bottom line: We can predict about 32 percent of the difference in team scores by the shooting percentage. But we know, because we’ve shot hoops in the driveway before, or went through a basketball unit in PE in the third grade, that sure, being a good shooter is important, but how many times you shoot the ball is also important. If you’re a 100 percent shooter, that’s insane, but it probably means you took one shot. Congrats, you scored two points (three if you’re gutsy). One shot is not going to win a game.</p>
<p>In our feature engineering, we created another metric – points per posesssion. It’s a measure of efficiency – did you score when you had the ball? We created a rolling metric for this too.</p>
<p>To add it to our model, it’s as simple as just adding <code>+ rolling_ppp</code></p>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="multiple-regression.html#cb43-1" aria-hidden="true" tabindex="-1"></a>fit_lm <span class="ot">&lt;-</span> lm_model <span class="sc">%&gt;%</span></span>
<span id="cb43-2"><a href="multiple-regression.html#cb43-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(team_score <span class="sc">~</span> rolling_shooting_percentage <span class="sc">+</span> rolling_ppp, <span class="at">data =</span> game_train)</span>
<span id="cb43-3"><a href="multiple-regression.html#cb43-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-4"><a href="multiple-regression.html#cb43-4" aria-hidden="true" tabindex="-1"></a>trainresults <span class="ot">&lt;-</span> game_train <span class="sc">%&gt;%</span></span>
<span id="cb43-5"><a href="multiple-regression.html#cb43-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">bind_cols</span>(<span class="fu">predict</span>(fit_lm, game_train))</span>
<span id="cb43-6"><a href="multiple-regression.html#cb43-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-7"><a href="multiple-regression.html#cb43-7" aria-hidden="true" tabindex="-1"></a><span class="fu">metrics</span>(trainresults, <span class="at">truth =</span> team_score, <span class="at">estimate =</span> .pred)</span></code></pre></div>
<pre><code>## # A tibble: 3 × 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 rmse    standard       9.97 
## 2 rsq     standard       0.445
## 3 mae     standard       7.77</code></pre>
<p>And just like that, by acknowledging reality, we’ve jumped to 44 percent of variance explained and our root mean squared error – the average amount we’re off by – has dropped from 11 to 10.</p>
<p>Your temptation now is to start adding things until we get to 1 on the r-squared and 0 on the rmse. The problem with that is called “overfitting”</p>
<p>Overfitting is where you produce a model that is too close to your training data, which makes it prone to fail with data you’ve never seen before – the model becomes unreliable when it’s not the training data anymore.</p>
<p>A secondary problem you encounter is this: the point of this is to predict future events. In this class, we’re attempting to predict the outcome of things that have not yet happened. That means we are going to be estimating the inputs to these models, inputs that will no doubt have error. So our inputs have a range of possible outcomes, our model is not perfect, so the outcome is going to combine the two. The more elements of your model that you use as inputs, the more error – uncertainty – you are introducing.</p>
<p>The point is you want to pick the things that really matter and ignore the rest in some vain quest to get to 100 percent. You won’t get there.</p>
</div>
<div id="picking-what-moves-the-needle" class="section level2" number="3.2">
<h2><span class="header-section-number">3.2</span> Picking what moves the needle</h2>
<p>There are multiple ways to find the right combination of inputs to your models. With multiple regressions, the most common is the correlation matrix. We’re looking to maximize r-squared by choosing inputs that are highly correlated to our target value, but <em>not</em> correlated with other things. Example: We can assume that field_goals_made and field_goal_pct are highly correlated to team_score, but the number of Field Goals made is also highly correlated with the field goal percentage.</p>
<p>Using <code>corrr</code>, we can create a correlation matrix in a dataframe to find columns that are highly correlated with our target – team_score. To do this, we need to select the columns we’re working with – our three rolling metrics.</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="multiple-regression.html#cb45-1" aria-hidden="true" tabindex="-1"></a>teamstats <span class="sc">%&gt;%</span> </span>
<span id="cb45-2"><a href="multiple-regression.html#cb45-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(team_score, rolling_shooting_percentage, rolling_ppp, rolling_true_shooting_percentage) <span class="sc">%&gt;%</span> </span>
<span id="cb45-3"><a href="multiple-regression.html#cb45-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">correlate</span>()</span></code></pre></div>
<pre><code>## # A tibble: 4 × 5
##   term          team_score rolling_shooting_pe… rolling_ppp rolling_true_shooti…
##   &lt;chr&gt;              &lt;dbl&gt;                &lt;dbl&gt;       &lt;dbl&gt;                &lt;dbl&gt;
## 1 team_score        NA                    0.566       0.665                0.597
## 2 rolling_shoo…      0.566               NA           0.817                0.930
## 3 rolling_ppp        0.665                0.817      NA                    0.864
## 4 rolling_true…      0.597                0.930       0.864               NA</code></pre>
<p>Reading this can be a lot, and it helps to take some notes as you go.</p>
<p>You read up and down and left and right – it’s a matrix. Follow the rolling_true_shooting_percentage row across to the rolling_shooting_percentage column and you’ll see they’re almost perfectly correlated with each other – 1 is a perfect correlation.</p>
<p>What does that mean? It means including both is going to just add error without adding much value. They’re so similar. You pick the one that is more highly correlated with team_score – true shooting.</p>
<p>So how does this look in a model? Since we already have the features – the columns – in our data and we have it split into training and testing, we just need to create a new fit.</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="multiple-regression.html#cb47-1" aria-hidden="true" tabindex="-1"></a>new_fit_lm <span class="ot">&lt;-</span> lm_model <span class="sc">%&gt;%</span></span>
<span id="cb47-2"><a href="multiple-regression.html#cb47-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(team_score <span class="sc">~</span> rolling_true_shooting_percentage <span class="sc">+</span> rolling_ppp, <span class="at">data =</span> game_train)</span></code></pre></div>
<p>Let’s take a peek at our model coefficients.</p>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb48-1"><a href="multiple-regression.html#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy</span>(new_fit_lm, <span class="at">conf.int =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>## # A tibble: 3 × 7
##   term                  estimate std.error statistic  p.value conf.low conf.high
##   &lt;chr&gt;                    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;
## 1 (Intercept)             -0.532    0.323      -1.65 9.98e- 2   -1.17      0.102
## 2 rolling_true_shootin…    0.180    0.0117     15.4  1.24e-53    0.157     0.203
## 3 rolling_ppp             60.6      0.577     105.   0          59.5      61.8</code></pre>
<p>What this says is if we can manage one point per possession in a basketball game, we’ll score 60 points. The model says for each 10 points of true shooting percentage, we’ll add another 1.8 points. Now we play the games.</p>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb50-1"><a href="multiple-regression.html#cb50-1" aria-hidden="true" tabindex="-1"></a>newtrainresults <span class="ot">&lt;-</span> game_train <span class="sc">%&gt;%</span></span>
<span id="cb50-2"><a href="multiple-regression.html#cb50-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">bind_cols</span>(<span class="fu">predict</span>(new_fit_lm, game_train))</span></code></pre></div>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="multiple-regression.html#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="fu">metrics</span>(newtrainresults, <span class="at">truth =</span> team_score, <span class="at">estimate =</span> .pred)</span></code></pre></div>
<pre><code>## # A tibble: 3 × 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 rmse    standard       9.97 
## 2 rsq     standard       0.445
## 3 mae     standard       7.76</code></pre>
<p>So … we’re up to an r-squared of .44 and an rmse under 10. The goal here is to add to r-squared and reduce our error metrics.</p>
<p>How well does the model do with data it hasn’t seen before?</p>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb53-1"><a href="multiple-regression.html#cb53-1" aria-hidden="true" tabindex="-1"></a>testresults <span class="ot">&lt;-</span> game_test <span class="sc">%&gt;%</span></span>
<span id="cb53-2"><a href="multiple-regression.html#cb53-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">bind_cols</span>(<span class="fu">predict</span>(fit_lm, game_test))</span></code></pre></div>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb54-1"><a href="multiple-regression.html#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="fu">metrics</span>(testresults, <span class="at">truth =</span> team_score, <span class="at">estimate =</span> .pred)</span></code></pre></div>
<pre><code>## # A tibble: 3 × 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 rmse    standard       9.85 
## 2 rsq     standard       0.440
## 3 mae     standard       7.70</code></pre>
<p>It’s remarkably stable. Our rmse is all but unchanged as is our r-squared. Until we find other metrics or other methods, this is solid.</p>
<p>Let’s put this against a set of games we’re familiar with.</p>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="multiple-regression.html#cb56-1" aria-hidden="true" tabindex="-1"></a>nu <span class="ot">&lt;-</span> teamstats <span class="sc">%&gt;%</span> </span>
<span id="cb56-2"><a href="multiple-regression.html#cb56-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(season <span class="sc">==</span> <span class="dv">2022</span>, team_short_display_name <span class="sc">==</span> <span class="st">&quot;Nebraska&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb57"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb57-1"><a href="multiple-regression.html#cb57-1" aria-hidden="true" tabindex="-1"></a>nupreds <span class="ot">&lt;-</span> nu <span class="sc">%&gt;%</span></span>
<span id="cb57-2"><a href="multiple-regression.html#cb57-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">bind_cols</span>(<span class="fu">predict</span>(new_fit_lm, nu))</span></code></pre></div>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb58-1"><a href="multiple-regression.html#cb58-1" aria-hidden="true" tabindex="-1"></a>nupreds <span class="sc">%&gt;%</span> </span>
<span id="cb58-2"><a href="multiple-regression.html#cb58-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">residual =</span> team_score <span class="sc">-</span> .pred) <span class="sc">%&gt;%</span> </span>
<span id="cb58-3"><a href="multiple-regression.html#cb58-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">arrange</span>(<span class="fu">desc</span>(residual)) <span class="sc">%&gt;%</span> </span>
<span id="cb58-4"><a href="multiple-regression.html#cb58-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(game_date, team_short_display_name, opponent_name, team_score, .pred, residual)</span></code></pre></div>
<pre><code>## # A tibble: 25 × 6
##    game_date  team_short_display_name opponent_name    team_score .pred residual
##    &lt;date&gt;     &lt;chr&gt;                   &lt;chr&gt;                 &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;
##  1 2021-12-02 Nebraska                NC State                100  71.9    28.1 
##  2 2021-12-23 Nebraska                Kennesaw State           88  72.2    15.8 
##  3 2022-02-02 Nebraska                Michigan                 79  66.6    12.4 
##  4 2022-01-03 Nebraska                Ohio State               79  67.2    11.8 
##  5 2021-12-08 Nebraska                Michigan                 67  56.5    10.5 
##  6 2022-02-10 Nebraska                Minnesota                78  68.0    10.0 
##  7 2021-11-10 Nebraska                Western Illinois         74  65.7     8.30
##  8 2021-11-13 Nebraska                Sam Houston              74  68.9     5.14
##  9 2022-02-13 Nebraska                Iowa                     75  70.1     4.89
## 10 2021-11-27 Nebraska                South Dakota             83  78.3     4.74
## # … with 15 more rows</code></pre>
<p>The question to start thinking about is this – what else could we include?</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="the-modeling-process-and-linear-regression.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="decision-trees-and-random-forests.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/02-multipleregression.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["advancedsportsdataanalysis.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
